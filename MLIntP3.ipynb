{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "# takes a lilbit\n",
    "# model = models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True, limit=500000)  \n",
    "model = models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True, limit=500000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and permanent stuff\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "list_of_scrape_times = []\n",
    "list_of_types = ['text','log','contact','calender','file','tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ELEMENTWISE FEATURIZING FUNCTION DEFINITIONS\n",
    "\n",
    "# takes in element of list_of_jsons and scrape date, spits out text frequency \n",
    "def textFreq(texts, scrapedate):\n",
    "    \n",
    "    a = texts.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    text_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        text_date = int(json.loads(a[len(a)-(i+1)])['date'].encode('ascii','ignore'))\n",
    "        if (two_weeks_prior < text_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    return float(saved_index+1)/14\n",
    "    \n",
    "    \n",
    "# takes in element of list_of_jsons(resp object) and scrape date, spits out call frequency \n",
    "def callFreq(calls, scrapedate):\n",
    "    \n",
    "    a = calls.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    call_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        call_date = int(json.loads(a[len(a)-(i+1)])['date'].encode('ascii','ignore'))\n",
    "        if (two_weeks_prior < call_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    return float(saved_index+1)/14\n",
    "\n",
    "\n",
    "## WORD2VEC BB\n",
    "\n",
    "# input is tweet, returns vector embedding of entire tweet.\n",
    "# eg: a3.json()[0]\n",
    "def tweetToEmbedding(tweet):\n",
    "    \n",
    "    q = json.loads(tweet)['text'].split()\n",
    "    \n",
    "    sumVector = np.zeros((300,))\n",
    "\n",
    "    for i in range(0,len(q)):\n",
    "        try:\n",
    "            sumVector += model[q[i]]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return sumVector\n",
    "\n",
    "#input is tweets, return master vector\n",
    "def embeddingToMastersum(tweets):\n",
    "    \n",
    "    masterSum = np.zeros((300,))\n",
    "    \n",
    "    for i in range(0,10):\n",
    "        try:\n",
    "            masterSum += tweetToEmbedding(tweets.json()[i])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return masterSum\n",
    "\n",
    "#input is tweets, return follocount\n",
    "def followerCount(tweets):\n",
    "\n",
    "    followerCount = 0\n",
    "    \n",
    "    try:\n",
    "        followerCount = json.loads(tweets.json()[0])['user']['followers_count']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    return followerCount\n",
    "\n",
    "#input is tweets, return friends (who user follows)\n",
    "def followingCount(tweets):\n",
    "\n",
    "    followingCount = 0\n",
    "    \n",
    "    try:\n",
    "        followingCount = json.loads(tweets.json()[0])['user']['friends_count']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    return followingCount\n",
    "\n",
    "#input is tweets, return avg likes per post for the last 2 weeks\n",
    "def twitterLikeFreq(tweets, scrapedate):\n",
    "\n",
    "    a = tweets.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    tweet_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "        utc = json.loads(a[len(a)-(i+1)])['created_at']\n",
    "        \n",
    "        tweet_date = int(time.mktime(time.strptime(utc,\"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        \n",
    "        if (two_weeks_prior < tweet_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    sum_of_likes = 0\n",
    "    \n",
    "    for i in range(0, saved_index):\n",
    "        sum_of_likes += json.loads(tweets.json()[i])['favorite_count']\n",
    "    \n",
    "    \n",
    "    return sum_of_likes/14\n",
    "    \n",
    "#input is tweets, return avg retweets per post for the last 2 weeks\n",
    "def twitterRetweetFreq(tweets, scrapedate):\n",
    "\n",
    "    a = tweets.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    tweet_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        \n",
    "        utc = json.loads(a[len(a)-(i+1)])['created_at']\n",
    "        \n",
    "        tweet_date = int(time.mktime(time.strptime(utc,\"%a %b %d %H:%M:%S +0000 %Y\")))\n",
    "        \n",
    "        if (two_weeks_prior < tweet_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    sum_of_retweets = 0\n",
    "    \n",
    "    for i in range(0, saved_index):\n",
    "        sum_of_likes += json.loads(tweets.json()[i])['retweet_count']\n",
    "    \n",
    "    \n",
    "    return sum_of_retweets/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://depressionmqp.wpi.edu:8080/getids')\n",
    "list_of_idtime = r.json()\n",
    "list_of_ids = []\n",
    "list_of_times = []\n",
    "\n",
    "for i in range(0,len(list_of_idtime)):\n",
    "    list_of_ids.append( list_of_idtime[i]['id'].encode('ascii','ignore') )\n",
    "    \n",
    "for i in range(0,len(list_of_idtime)):\n",
    "    list_of_times.append( list_of_idtime[i]['date'] )\n",
    "\n",
    "#id1 = list_of_ids[0].encode('ascii','ignore')\n",
    "\n",
    "number_cols = len(list_of_types)\n",
    "number_rows = len(list_of_ids)\n",
    "list_of_jsons = [[0] * number_cols for i in range(number_rows)]\n",
    "\n",
    "\n",
    "### create directory for this particular scrape\n",
    "timenow  = str(int(time.time())) # for temporal congruency\n",
    "list_of_scrape_times.append(timenow)\n",
    "os.mkdir('./datafor' + timenow)\n",
    "filedir = './datafor' + timenow\n",
    "\n",
    "\n",
    "for i in range(0,number_rows):\n",
    "    for j in range(0,number_cols):\n",
    "        temp = requests.get('http://depressionmqp.wpi.edu:8080/getdata?id=' + str(int(list_of_ids[0])) + '&type=' + list_of_types[j])\n",
    "        \n",
    "        pickle.dump(temp, open( filedir + \"/DP\" + str(int(list_of_ids[i])) +  list_of_types[j] + \".p\", \"wb\" ))\n",
    "        \n",
    "        # loads it into memory. i will not use this for now\n",
    "        # for architectural sanity\n",
    "        # list_of_jsons[i][j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DELETE DIRECTORY CELL\n",
    "\n",
    "import shutil\n",
    "\n",
    "def deletdatboi(nombre):\n",
    "    shutil.rmtree('./datafor' + list_of_scrape_times[nombre])\n",
    "\n",
    "#deletdatboi(1)\n",
    "\n",
    "list_of_scrape_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_of_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-458b3e7434da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_of_people\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatureVectorCF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_people\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatureVectorTF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_people\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatureVectorTW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_people\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_of_ids' is not defined"
     ]
    }
   ],
   "source": [
    "num_of_people = len(list_of_ids)\n",
    "\n",
    "featureVectorCF = np.zeros((num_of_people,1))\n",
    "featureVectorTF = np.zeros((num_of_people,1))\n",
    "featureVectorTW = np.zeros((num_of_people,300))\n",
    "featureVectorFC = np.zeros((num_of_people,1))\n",
    "featureVectorFC2 = np.zeros((num_of_people,1))\n",
    "featureVectorTWL = np.zeros((num_of_people,1))\n",
    "featureVectorTWRT = np.zeros((num_of_people,1))\n",
    "\n",
    "\n",
    "for i in range(0, num_of_people):\n",
    "    \n",
    "    list_of_jsons[i][1]\n",
    "    \n",
    "    a1 = pickle.load( open( filedir + \"/DP\" + str(int(list_of_ids[i])) +  \"log\" + \".p\", \"rb\" )) \n",
    "    a2 = pickle.load( open( filedir + \"/DP\" + str(int(list_of_ids[i])) +  \"text\" + \".p\", \"rb\" )) \n",
    "    a3 = pickle.load( open( filedir + \"/DP\" + str(int(list_of_ids[i])) +  \"tweets\" + \".p\", \"rb\" )) \n",
    "\n",
    "    \n",
    "    featureVectorCF[i] = callFreq(a1, list_of_times[i])\n",
    "    featureVectorTF[i] = textFreq(a2, list_of_times[i])\n",
    "    featureVectorTW[i] = embeddingToMastersum(a3)\n",
    "    featureVectorFC[i] = followerCount(a3)\n",
    "    featureVectorFC2[i] = followingCount(a3)\n",
    "    featureVectorTWL[i] = twitterLikeFreq(a3, list_of_times[i])\n",
    "    featureVectorTWRT[i] = twitterRetweetFreq(a3, list_of_times[i])\n",
    "\n",
    "    \n",
    "featureMatrix = np.hstack((featureVectorCF,featureVectorTF, featureVectorTW, featureVectorFC, featureVectorTWL, featureVectorTWRT))\n",
    "\n",
    "featureMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Sun Nov 12 14:29:22 +0000 2017',\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'urls': [{'display_url': 'twitter.com/usembassymanil…',\n",
       "    'expanded_url': 'https://twitter.com/usembassymanila/status/929684767087378432',\n",
       "    'indices': [11, 34],\n",
       "    'url': 'https://t.co/TD0rYcWN8C'}],\n",
       "  'user_mentions': []},\n",
       " 'favorite_count': 40818,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 929717762422988800,\n",
       " 'id_str': '929717762422988801',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': True,\n",
       " 'lang': 'en',\n",
       " 'place': None,\n",
       " 'possibly_sensitive': False,\n",
       " 'quoted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Sun Nov 12 12:18:15 +0000 2017',\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'urls': [{'display_url': 'twitter.com/i/web/status/9…',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/929684767087378432',\n",
       "     'indices': [117, 140],\n",
       "     'url': 'https://t.co/S08LrQFSpr'}],\n",
       "   'user_mentions': []},\n",
       "  'favorite_count': 3984,\n",
       "  'favorited': False,\n",
       "  'geo': None,\n",
       "  'id': 929684767087378400,\n",
       "  'id_str': '929684767087378432',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'en',\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 1231,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  'text': 'President Trump has arrived in the Philippines to attend the 31st ASEAN Summit and Related Summits. Welcome and mab… https://t.co/S08LrQFSpr',\n",
       "  'truncated': True,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Wed Sep 30 02:28:08 +0000 2009',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'description': 'Official Twitter account of the U.S. Embassy in the Philippines',\n",
       "   'entities': {'description': {'urls': []},\n",
       "    'url': {'urls': [{'display_url': 'ph.usembassy.gov',\n",
       "       'expanded_url': 'http://ph.usembassy.gov',\n",
       "       'indices': [0, 23],\n",
       "       'url': 'https://t.co/vi2hcq3zUk'}]}},\n",
       "   'favourites_count': 6305,\n",
       "   'follow_request_sent': False,\n",
       "   'followers_count': 773879,\n",
       "   'following': False,\n",
       "   'friends_count': 1456,\n",
       "   'geo_enabled': False,\n",
       "   'has_extended_profile': False,\n",
       "   'id': 78489442,\n",
       "   'id_str': '78489442',\n",
       "   'is_translation_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'lang': 'en',\n",
       "   'listed_count': 914,\n",
       "   'location': 'Manila, Philippines',\n",
       "   'name': 'U.S. Embassy in the Philippines',\n",
       "   'notifications': False,\n",
       "   'profile_background_color': '3B94D9',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme13/bg.gif',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme13/bg.gif',\n",
       "   'profile_background_tile': True,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/78489442/1510467205',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/444623397/crossed_flag_001_normal.JPG',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/444623397/crossed_flag_001_normal.JPG',\n",
       "   'profile_link_color': '0091FF',\n",
       "   'profile_sidebar_border_color': 'FFFFFF',\n",
       "   'profile_sidebar_fill_color': 'FFFFFF',\n",
       "   'profile_text_color': '333333',\n",
       "   'profile_use_background_image': False,\n",
       "   'protected': False,\n",
       "   'screen_name': 'usembassymanila',\n",
       "   'statuses_count': 15334,\n",
       "   'time_zone': 'Hong Kong',\n",
       "   'translator_type': 'none',\n",
       "   'url': 'https://t.co/vi2hcq3zUk',\n",
       "   'utc_offset': 28800,\n",
       "   'verified': True}},\n",
       " 'quoted_status_id': 929684767087378400,\n",
       " 'quoted_status_id_str': '929684767087378432',\n",
       " 'retweet_count': 7547,\n",
       " 'retweeted': False,\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'text': 'Thank you! https://t.co/TD0rYcWN8C',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Wed Mar 18 13:46:38 +0000 2009',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': '45th President of the United States of America🇺🇸',\n",
       "  'entities': {'description': {'urls': []},\n",
       "   'url': {'urls': [{'display_url': 'Instagram.com/realDonaldTrump',\n",
       "      'expanded_url': 'http://www.Instagram.com/realDonaldTrump',\n",
       "      'indices': [0, 23],\n",
       "      'url': 'https://t.co/OMxB0x7xC5'}]}},\n",
       "  'favourites_count': 23,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 42540307,\n",
       "  'following': False,\n",
       "  'friends_count': 45,\n",
       "  'geo_enabled': True,\n",
       "  'has_extended_profile': False,\n",
       "  'id': 25073877,\n",
       "  'id_str': '25073877',\n",
       "  'is_translation_enabled': True,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 80189,\n",
       "  'location': 'Washington, DC',\n",
       "  'name': 'Donald J. Trump',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': '6D5C18',\n",
       "  'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/530021613/trump_scotland__43_of_70_cc.jpg',\n",
       "  'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/530021613/trump_scotland__43_of_70_cc.jpg',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/25073877/1510414100',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/874276197357596672/kUuht00m_normal.jpg',\n",
       "  'profile_link_color': '1B95E0',\n",
       "  'profile_sidebar_border_color': 'BDDCAD',\n",
       "  'profile_sidebar_fill_color': 'C5CEC0',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'realDonaldTrump',\n",
       "  'statuses_count': 36366,\n",
       "  'time_zone': 'Eastern Time (US & Canada)',\n",
       "  'translator_type': 'regular',\n",
       "  'url': 'https://t.co/OMxB0x7xC5',\n",
       "  'utc_offset': -18000,\n",
       "  'verified': True}}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## access example\n",
    "a3 = pickle.load( open( filedir + \"/DP\" + str(int(list_of_ids[0])) +  \"tweets\" + \".p\", \"rb\" )) \n",
    "json.loads(a3.json()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = embeddingToMastersum(a3)\n",
    "w.reshape((-1, 1)).T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = json.loads(a3.json()[1])['text'].split()\n",
    "#a3.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sun', 'Nov', '12', '14:29:22', '+0000', '2017']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "utc = json.loads(a3.json()[0])['created_at']\n",
    "r = utc.split()\n",
    "r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510514962\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(int(time.mktime(time.strptime(utc,\"%a %b %d %H:%M:%S +0000 %Y\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
