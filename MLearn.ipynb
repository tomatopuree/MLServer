{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n gives nth phq answer\n",
    "# 10 gives sum of all phqs\n",
    "def Yer(y, n):\n",
    "    return y[:,n-1:n]\n",
    "\n",
    "\n",
    "contactsStartEnd = [0,1]\n",
    "twitterStartEnd = [1,5]\n",
    "textStartEnd = [5,78]\n",
    "callStartEnd = [78,92]\n",
    "instagramStartEnd = [92,110]\n",
    "# gpsStartEnd = [110,113]\n",
    "\n",
    "audioStartEnd = [110,1693]\n",
    "\n",
    "allStartEnd = [contactsStartEnd[0], audioStartEnd[1]]\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "\n",
    "# ftype = \"au\" audio / \"ig\" instagram / \"txt\" text / \"con\" contacts / \"tw\" twitter / \"call\" call\n",
    "# \"all\" = big matrix\n",
    "def Xer(X, ftype):\n",
    "    if(ftype == \"au\"):\n",
    "        return X[:,audioStartEnd[0]:audioStartEnd[1]]\n",
    "    if(ftype == \"ig\"):\n",
    "        return X[:,instagramStartEnd[0]:instagramStartEnd[1]]\n",
    "    if(ftype == \"txt\"):\n",
    "        return X[:,textStartEnd[0]:textStartEnd[1]]\n",
    "    if(ftype == \"con\"):\n",
    "        return X[:,contactsStartEnd[0]:contactsStartEnd[1]]\n",
    "    if(ftype == \"tw\"):\n",
    "        return X[:,twitterStartEnd[0]:twitterStartEnd[1]]\n",
    "    if(ftype == \"call\"):\n",
    "        return X[:,callStartEnd[0]:callStartEnd[1]]\n",
    "#     if(ftype == \"gps\"):\n",
    "#         return X[:,gpsStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"all\"):\n",
    "        return X[:,allStartEnd[0]:allStartEnd[1]]\n",
    "    if(ftype == \"audioless\"):\n",
    "        return X[:,allStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"gpsless\"):\n",
    "        return np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## PREPROCESSING\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "mtr = pd.read_csv(\"mtr1.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "#mtr.shape\n",
    "\n",
    "## PREPROCESSING\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# shuffle row-wise\n",
    "np.random.shuffle(mtr)\n",
    "\n",
    "data = mtr[:,allStartEnd[0]:allStartEnd[1]]\n",
    "# data = np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))\n",
    "\n",
    "\n",
    "labels = mtr[:,1693:1704]\n",
    "\n",
    "\n",
    "# replace missing values with mean of their corresponding features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# If NaNs should be dropped instead:\n",
    "# mtr = mtr[~np.isnan(mtr).any(axis=1)]\n",
    "\n",
    "# normalize data (features now have gauss dist., 0 mean and unit variance)\n",
    "data = sklearn.preprocessing.scale(data)\n",
    "\n",
    "\n",
    "# THIS IS AN ALTERNATIVE TO 0 MEAN UNIT VARIANCE NORMALIZATION\n",
    "# do this to scale features to range 0-1\n",
    "# this must be done if a chi^2 is being performed\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data = min_max_scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATA SPLIT (#nosnooping)\n",
    "\n",
    "# TEST DATA (%15 percent of data)\n",
    "numofppl_index = mtr.shape[0] - 1\n",
    "cut_index = int(mtr.shape[0] * 0.85)\n",
    "\n",
    "test_label = labels[cut_index:numofppl_index,:]\n",
    "test_data = data[cut_index:numofppl_index,:]\n",
    "\n",
    "# TRAINING AND VALIDATION DATA (%85 percent of data)\n",
    "\n",
    "train_label = labels[0:cut_index,:]\n",
    "train_data = data[0:cut_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  3.,  1., 25.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0., ...,  2.,  1., 16.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  0., ...,  1.,  2., 11.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0., 14.],\n",
       "       [ 1.,  1.,  1., ...,  3.,  3., 25.]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[1] # 15\n",
    "train_label[2] # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing for 15\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,1:2]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,1:2]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,1:2] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,1:2]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,1:2] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,1:2]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balancing for 20\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,2:3]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,2:3]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,2:3] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,2:3]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,2:3] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,2:3]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balancing for 10\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,0:1]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,0:1]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,0:1] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,0:1]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,0:1] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,0:1]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 1)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_15_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Xer(train_data_15_bal, ftypes[i])\n",
    "y = train_label_15_bal.reshape(255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutoff(train_label):\n",
    "\n",
    "    phqcutoffs = [10,15,20]\n",
    "\n",
    "    for j in range(0,len(phqcutoffs)):\n",
    "        for i in range(0,train_label[:,9:10].shape[0]):\n",
    "            if(train_label[i][9] > phqcutoffs[j]):\n",
    "                train_label[i][j] = 1\n",
    "            else:\n",
    "                train_label[i][j] = 0\n",
    "               \n",
    "    train_label_x = train_label\n",
    "        \n",
    "    return train_label_x               \n",
    "\n",
    "def YerCutOff(y, cutoff):\n",
    "    if (cutoff == 10):\n",
    "        return y[:,0:1]\n",
    "    if (cutoff == 15):\n",
    "        return y[:,1:2]\n",
    "    if (cutoff == 20):\n",
    "        return y[:,2:3]\n",
    "    \n",
    "train_label = cutoff(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "#             X = Xer(train_data, ftypes[i])\n",
    "#             y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            X = Xer(train_data_15_bal, ftypes[i])\n",
    "            y = train_label_15_bal.reshape(54,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            svc = svm.SVC()\n",
    "\n",
    "            grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au   ig       txt       con   tw      call       all\n",
       "0  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519\n",
       "1  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'kernel': ('linear', 'rbf', 'poly', 'sigmoid')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Xer(train_data_15_bal,\"all\")\n",
    "y = train_label_15_bal.reshape(256,)\n",
    "\n",
    "c_range = list(range(1, 15))\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'sigmoid',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.89      0.82       128\n",
      "        1.0       0.87      0.72      0.79       128\n",
      "\n",
      "avg / total       0.81      0.80      0.80       256\n",
      "\n",
      "[[114  14]\n",
      " [ 36  92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "grid.best_score_\n",
    "predictions = grid.predict(X)\n",
    "print(classification_report(y, predictions))\n",
    "print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'poly',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "            X = Xer(train_data, ftypes[i])\n",
    "            y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            \n",
    "            min_sample_leaf = list(range(50,52))\n",
    "            parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "            \n",
    "            rfc = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "\n",
    "            grid = GridSearchCV(rfc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au        ig       txt       con        tw      call       all\n",
       "0  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882\n",
       "1  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 50,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf1 = svm.SVC(C=1, kernel=\"rbf\") #au\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90 (+/- 0.00) [randyforst]\n",
      "Accuracy: 0.90 (+/- 0.00) [svm classifier]\n",
      "Accuracy: 0.90 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "clf2 = svm.SVC(C=2, kernel=\"rbf\", probability=True)\n",
    "\n",
    "np.random.seed(123)\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2], weights=[1,1])\n",
    "\n",
    "X = Xer(train_data, ftypes[i])\n",
    "y = YerCutOff(train_label, 20).reshape(255,)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, eclf], ['randyforst', 'svm classifier', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      1.00      0.95       229\n",
      "        1.0       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.81      0.90      0.85       255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "eclf.fit(X, y)\n",
    "\n",
    "# grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "# grid.best_score_\n",
    "predictions = eclf.predict(X)\n",
    "print(classification_report(y, predictions))\n",
    "# print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 CUTOFF ENSEMBLE WEIRD TRY\n",
    "\n",
    "clf1 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #au\n",
    "clf2 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #ig\n",
    "clf3 = svm.SVC(C=1, kernel=\"sigmoid\" , probability=True) #txt\n",
    "clf4 = svm.SVC(C=2, kernel=\"rbf\" , probability=True) # con\n",
    "clf5 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) # tw\n",
    "clf6 = svm.SVC(C=1, kernel=\"rbf\", probability=True) # call\n",
    "\n",
    "\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6], weights=[1,1,1,1,1,1])\n",
    "\n",
    "scores = []\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "for i in range(0,len(ftypes)):\n",
    "    X = Xer(train_data, ftypes[i])\n",
    "    y = YerCutOff(train_label, 15).reshape(255,)\n",
    "\n",
    "    scores.append(cross_validation.cross_val_score(eclf, X, y, cv=2, scoring='accuracy'))\n",
    "\n",
    "\n",
    "# for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "#     scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.703125  , 0.70866142]),\n",
       " array([0.703125 , 0.7007874]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125 , 0.7007874]),\n",
       " array([0.703125  , 0.70866142])]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class EnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Ensemble classifier for scikit-learn estimators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    clf : `iterable`\n",
    "      A list of scikit-learn classifier objects.\n",
    "    weights : `list` (default: `None`)\n",
    "      If `None`, the majority rule voting will be applied to the predicted class labels.\n",
    "        If a list of weights (`float` or `int`) is provided, the averaged raw probabilities (via `predict_proba`)\n",
    "        will be used to determine the most confident class label.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, clfs, weights=None):\n",
    "        self.clfs = clfs\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the scikit-learn estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "            Training data\n",
    "        y : list or numpy array, shape = [n_samples]\n",
    "            Class labels\n",
    "\n",
    "        \"\"\"\n",
    "        for clf in self.clfs:\n",
    "            clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "\n",
    "        maj : list or numpy array, shape = [n_samples]\n",
    "            Predicted class labels by majority rule\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.classes_ = np.asarray([clf.predict(X) for clf in self.clfs])\n",
    "        if self.weights:\n",
    "            avg = self.predict_proba(X)\n",
    "\n",
    "            maj = np.apply_along_axis(lambda x: max(enumerate(x), key=operator.itemgetter(1))[0], axis=1, arr=avg)\n",
    "\n",
    "        else:\n",
    "            maj = np.asarray([np.argmax(np.bincount(self.classes_[:,c])) for c in range(self.classes_.shape[1])])\n",
    "\n",
    "        return maj\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "\n",
    "        avg : list or numpy array, shape = [n_samples, n_probabilities]\n",
    "            Weighted average probability for each class per sample.\n",
    "\n",
    "        \"\"\"\n",
    "        self.probas_ = [clf.predict_proba(X) for clf in self.clfs]\n",
    "        avg = np.average(self.probas_, axis=0, weights=self.weights)\n",
    "\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CUSTOM CLASSIFIER\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class Binner(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, regressor):\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regressor.fit(X, y)\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        prediction = self.regressor.predict(X)\n",
    "        \n",
    "        if (prediction[0] > 15):\n",
    "            return np.asarray([1])\n",
    "        else:\n",
    "            return np.asarray([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "# rdc.fit(X,y)\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "bnr = Binner(rdc)\n",
    "bnr.fit(X,y)\n",
    "a = bnr.predict(X[0:1,:])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-de36b9e45e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m pipeline = Pipeline([\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'regr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     ('binner', binner)])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binner' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('regr', RandomForestRegressor(random_state=0, max_features=None)),\n",
    "    ('binner', binner)])\n",
    "    \n",
    "def binner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-c4406b5af5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, X, y, classifier)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0;31m# the test split can be too big because we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "bnr = Binner(rdc)\n",
    "score = cross_validation.cross_val_score(bnr, X, y, cv=2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_leaf': [50, 51], 'n_estimators': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ RANDOM FOREST FEATURE SELECTION #############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "# rdc = RandomForestRegressor(max_depth=2, random_state=0)#,max_features=None)\n",
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "\n",
    "# clf.fit(X, y)\n",
    "\n",
    "n_estimators = list(range(500,501))\n",
    "max_features = [\"auto\",\"sqrt\",\"log2\",0.2,0.4,0.6,0.8,None]\n",
    "min_sample_leaf = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "max_depth = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rdc, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde36434c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lizz = train_label[:,9:10].tolist()\n",
    "lizzn = []\n",
    "for i in range(0,len(lizz)):\n",
    "    lizzn.append(lizz[i][0])\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "Counter(lizzn)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels, values = zip(*Counter(lizzn).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.156e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.078e-03, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=1.010e-03, previous alpha=1.009e-03, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(255, 0), dtype=float64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "rlasso = RandomizedLasso()\n",
    "rlasso.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.075, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.02 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.01 , 0.005, 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.03 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.015, 0.   , 0.   , 0.   , 0.   , 0.01 , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.04 , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   ,\n",
       "       0.015, 0.   , 0.   , 0.   , 0.035, 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.03 ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.005, 0.   , 0.035, 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlasso.scores_[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1693)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xla = np.zeros((255, 1))\n",
    "\n",
    "for i in range(0,len(rlasso.scores_)):\n",
    "    if(rlasso.scores_[i] != 0):\n",
    "        Xla = np.hstack((Xla, X[:,i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xla = np.delete(Xla, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVC #############################\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "# parameters = {}\n",
    "\n",
    "# grid = GridSearchCV(regr, parameters, cv=2, scoring='explained_variance')\n",
    "# grid.fit(X, y)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "X = sel.fit_transform(X)\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':list([0.001,0.01,0.1,1,2,3,4,5,6,7,8,10])}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.76863, std: 0.01870, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: 0.75294, std: 0.01864, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: 0.82353, std: 0.07382, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: 0.72157, std: 0.01286, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.03042, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: 0.77255, std: 0.01479, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.01473, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: 0.74118, std: 0.02251, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: 0.69020, std: 0.01839, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 4, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 4, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 4, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 4, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 5, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 5, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 5, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 5, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 6, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 6, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 7, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 7, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 8, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 8, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: 0.65882, std: 0.01310, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n",
    "# grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.82      0.87       228\n",
      "        1.0       0.20      0.37      0.26        27\n",
      "\n",
      "avg / total       0.84      0.78      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xla)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 305)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(1.05))\n",
    "Xsel = sel.fit_transform(X)\n",
    "Xsel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xsel, y)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.81      0.86       230\n",
      "        1.0       0.17      0.36      0.23        25\n",
      "\n",
      "avg / total       0.85      0.77      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xsel)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liznb.index(max(liznb))\n",
    "max(liznb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_new = SelectKBest(chi2, k=100).fit_transform(X, y)\n",
    "# X_new.shape\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -48.36076, std: 4.91629, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: -48.48363, std: 5.11873, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: -48.47340, std: 5.10615, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: -48.48446, std: 5.11947, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: -48.30797, std: 4.56934, params: {'C': 0.005, 'kernel': 'linear'},\n",
       " mean: -48.47711, std: 5.11448, params: {'C': 0.005, 'kernel': 'rbf'},\n",
       " mean: -48.42917, std: 5.05056, params: {'C': 0.005, 'kernel': 'poly'},\n",
       " mean: -48.48173, std: 5.11783, params: {'C': 0.005, 'kernel': 'sigmoid'},\n",
       " mean: -48.84453, std: 3.90861, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: -48.46927, std: 5.10906, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: -48.36964, std: 4.99038, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: -48.47940, std: 5.11517, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: -55.87142, std: 2.88155, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: -48.33791, std: 5.02517, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: -48.36671, std: 4.72774, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: -48.32661, std: 4.86574, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: -86.93398, std: 13.02905, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: -48.09353, std: 4.93810, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: -49.11536, std: 3.98500, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: -49.10748, std: 3.86566, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: -102.49815, std: 15.76878, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: -48.76249, std: 5.03816, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: -48.99617, std: 4.14751, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: -50.06255, std: 4.14031, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: -112.84593, std: 15.88954, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: -49.93296, std: 4.56211, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: -49.04618, std: 4.33958, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: -51.04125, std: 4.20844, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: -139.56998, std: 35.20001, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: -53.95925, std: 3.78778, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: -50.51646, std: 3.49427, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: -57.70473, std: 1.94329, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVR #############################\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = Yer(train_label, 10).reshape(train_label.shape[0],)\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "c_range = [0.001,0.005,0.01,0.1,1,2,3,10]\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svr, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-48.09352610843258"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "import xml\n",
    "import xml.dom.minidom\n",
    "\n",
    "conn = sql.connect('phonedata.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "lizt = []\n",
    "gpsLookup = (1899, \"gps\")\n",
    "#for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "    \n",
    "#     print row[2]\n",
    "    lizt.append(row[2])\n",
    "    \n",
    "    \n",
    "#number of different places visited by the user\n",
    "def numDiff(lizt):\n",
    "    sum = 0\n",
    "    for i in range(0, len(lizt)):\n",
    "        a = lizt[i]\n",
    "        xmldoc = xml.dom.minidom.parseString(a)\n",
    "        kml = xmldoc.getElementsByTagName(\"kml\")[0]\n",
    "        document = kml.getElementsByTagName(\"Document\")[0]\n",
    "        placemarks = document.getElementsByTagName(\"Placemark\")\n",
    "        \n",
    "        for placemark in placemarks:\n",
    "            desc = placemark.getElementsByTagName(\"description\")[0].firstChild.data\n",
    "            sum = sum + 1\n",
    "            \n",
    "            #print desc\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "numDiff(lizt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Featurizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-deb9528a21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'./datafor19:36'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/DP\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"1899\"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\"gps\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Featurizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
