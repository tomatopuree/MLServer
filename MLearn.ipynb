{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n gives nth phq answer\n",
    "# 10 gives sum of all phqs\n",
    "def Yer(y, n):\n",
    "    return y[:,n-1:n]\n",
    "\n",
    "\n",
    "contactsStartEnd = [0,1]\n",
    "twitterStartEnd = [1,5]\n",
    "textStartEnd = [5,78]\n",
    "callStartEnd = [78,92]\n",
    "instagramStartEnd = [92,110]\n",
    "# gpsStartEnd = [110,113]\n",
    "\n",
    "audioStartEnd = [110,1693]\n",
    "\n",
    "allStartEnd = [contactsStartEnd[0], audioStartEnd[1]]\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "\n",
    "# ftype = \"au\" audio / \"ig\" instagram / \"txt\" text / \"con\" contacts / \"tw\" twitter / \"call\" call\n",
    "# \"all\" = big matrix\n",
    "def Xer(X, ftype):\n",
    "    if(ftype == \"au\"):\n",
    "        return X[:,audioStartEnd[0]:audioStartEnd[1]]\n",
    "    if(ftype == \"ig\"):\n",
    "        return X[:,instagramStartEnd[0]:instagramStartEnd[1]]\n",
    "    if(ftype == \"txt\"):\n",
    "        return X[:,textStartEnd[0]:textStartEnd[1]]\n",
    "    if(ftype == \"con\"):\n",
    "        return X[:,contactsStartEnd[0]:contactsStartEnd[1]]\n",
    "    if(ftype == \"tw\"):\n",
    "        return X[:,twitterStartEnd[0]:twitterStartEnd[1]]\n",
    "    if(ftype == \"call\"):\n",
    "        return X[:,callStartEnd[0]:callStartEnd[1]]\n",
    "#     if(ftype == \"gps\"):\n",
    "#         return X[:,gpsStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"all\"):\n",
    "        return X[:,allStartEnd[0]:allStartEnd[1]]\n",
    "    if(ftype == \"audioless\"):\n",
    "        return X[:,allStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"gpsless\"):\n",
    "        return np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## PREPROCESSING\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "mtr = pd.read_csv(\"mtr1.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "#mtr.shape\n",
    "\n",
    "## PREPROCESSING\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# shuffle row-wise\n",
    "np.random.shuffle(mtr)\n",
    "\n",
    "data = mtr[:,allStartEnd[0]:allStartEnd[1]]\n",
    "# data = np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))\n",
    "\n",
    "\n",
    "labels = mtr[:,1693:1704]\n",
    "\n",
    "\n",
    "# replace missing values with mean of their corresponding features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# If NaNs should be dropped instead:\n",
    "# mtr = mtr[~np.isnan(mtr).any(axis=1)]\n",
    "\n",
    "# normalize data (features now have gauss dist., 0 mean and unit variance)\n",
    "data = sklearn.preprocessing.scale(data)\n",
    "\n",
    "\n",
    "# THIS IS AN ALTERNATIVE TO 0 MEAN UNIT VARIANCE NORMALIZATION\n",
    "# do this to scale features to range 0-1\n",
    "# this must be done if a chi^2 is being performed\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data = min_max_scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATA SPLIT (#nosnooping)\n",
    "\n",
    "# TEST DATA (%15 percent of data)\n",
    "numofppl_index = mtr.shape[0] - 1\n",
    "cut_index = int(mtr.shape[0] * 0.85)\n",
    "\n",
    "test_label = labels[cut_index:numofppl_index,:]\n",
    "test_data = data[cut_index:numofppl_index,:]\n",
    "\n",
    "# TRAINING AND VALIDATION DATA (%85 percent of data)\n",
    "\n",
    "train_label = labels[0:cut_index,:]\n",
    "train_data = data[0:cut_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  3.,  1., 25.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0., ...,  2.,  1., 16.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  0., ...,  1.,  2., 11.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0., 14.],\n",
       "       [ 1.,  1.,  1., ...,  3.,  3., 25.]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[1] # 15\n",
    "train_label[2] # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing for 15\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,1:2]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,1:2]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,1:2] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,1:2]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,1:2] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,1:2]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "np.random.shuffle(train_label_15_bal)\n",
    "np.random.shuffle(train_data_15_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balancing for 20\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,2:3]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,2:3]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,2:3] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,2:3]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,2:3] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,2:3]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "np.random.shuffle(train_label_15_bal)\n",
    "np.random.shuffle(train_data_15_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing for 10\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,0:1]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,0:1]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,0:1] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,0:1]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,0:1] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,0:1]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "tempmtr =  np.hstack((train_data_15_bal, train_label_15_bal))\n",
    "np.random.shuffle(tempmtr)\n",
    "\n",
    "train_data_15_bal = tempmtr[:,0:1693]\n",
    "train_label_15_bal = tempmtr[:,1693:1694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1693)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_15_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Xer(train_data_15_bal, ftypes[i])\n",
    "y = train_label_15_bal.reshape(255,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cutoff(train_label):\n",
    "\n",
    "    phqcutoffs = [10,15,20]\n",
    "\n",
    "    for j in range(0,len(phqcutoffs)):\n",
    "        for i in range(0,train_label[:,9:10].shape[0]):\n",
    "            if(train_label[i][9] > phqcutoffs[j]):\n",
    "                train_label[i][j] = 1\n",
    "            else:\n",
    "                train_label[i][j] = 0\n",
    "               \n",
    "    train_label_x = train_label\n",
    "        \n",
    "    return train_label_x               \n",
    "\n",
    "def YerCutOff(y, cutoff):\n",
    "    if (cutoff == 10):\n",
    "        return y[:,0:1]\n",
    "    if (cutoff == 15):\n",
    "        return y[:,1:2]\n",
    "    if (cutoff == 20):\n",
    "        return y[:,2:3]\n",
    "    \n",
    "train_label = cutoff(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "#             X = Xer(train_data, ftypes[i])\n",
    "#             y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            X = Xer(train_data_15_bal, ftypes[i])\n",
    "            y = train_label_15_bal.reshape(54,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            svc = svm.SVC()\n",
    "\n",
    "            grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au   ig       txt       con   tw      call       all\n",
       "0  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519\n",
       "1  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1693)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_15_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.68      0.64       128\n",
      "        1.0       0.63      0.55      0.59       128\n",
      "\n",
      "avg / total       0.62      0.61      0.61       256\n",
      "\n",
      "[[87 41]\n",
      " [58 70]]\n"
     ]
    }
   ],
   "source": [
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "X = Xer(train_data_15_bal,\"txt\")\n",
    "y = train_label_15_bal.reshape(256,)\n",
    "\n",
    "# au gives 85\n",
    "\n",
    "# from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.001)\n",
    "rlasso.fit(X, y)\n",
    "X_lassod = rlasso.transform(X)\n",
    "X_lassod\n",
    "\n",
    "c_range = list(range(1, 15))\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(X_lassod, y)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "grid.best_score_\n",
    "predictions = grid.predict(X_lassod)\n",
    "print(classification_report(y, predictions))\n",
    "print(confusion_matrix(y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 91)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()\n",
    "X_lassod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.85      0.79       128\n",
      "        1.0       0.83      0.70      0.76       128\n",
      "\n",
      "avg / total       0.78      0.78      0.78       256\n",
      "\n",
      "[[109  19]\n",
      " [ 38  90]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'poly',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "            X = Xer(train_data, ftypes[i])\n",
    "            y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            \n",
    "            min_sample_leaf = list(range(50,52))\n",
    "            parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "            \n",
    "            rfc = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "\n",
    "            grid = GridSearchCV(rfc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au        ig       txt       con        tw      call       all\n",
       "0  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882\n",
       "1  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 50,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf1 = svm.SVC(C=1, kernel=\"rbf\") #au\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90 (+/- 0.00) [randyforst]\n",
      "Accuracy: 0.90 (+/- 0.00) [svm classifier]\n",
      "Accuracy: 0.90 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "clf2 = svm.SVC(C=2, kernel=\"rbf\", probability=True)\n",
    "\n",
    "np.random.seed(123)\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2], weights=[1,1])\n",
    "\n",
    "X = Xer(train_data, ftypes[i])\n",
    "y = YerCutOff(train_label, 20).reshape(255,)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, eclf], ['randyforst', 'svm classifier', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      1.00      0.95       229\n",
      "        1.0       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.81      0.90      0.85       255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "eclf.fit(X, y)\n",
    "\n",
    "# grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "# grid.best_score_\n",
    "predictions = eclf.predict(X)\n",
    "print(classification_report(y, predictions))\n",
    "# print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 CUTOFF ENSEMBLE WEIRD TRY\n",
    "\n",
    "clf1 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #au\n",
    "clf2 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #ig\n",
    "clf3 = svm.SVC(C=1, kernel=\"sigmoid\" , probability=True) #txt\n",
    "clf4 = svm.SVC(C=2, kernel=\"rbf\" , probability=True) # con\n",
    "clf5 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) # tw\n",
    "clf6 = svm.SVC(C=1, kernel=\"rbf\", probability=True) # call\n",
    "\n",
    "\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6], weights=[1,1,1,1,1,1])\n",
    "\n",
    "scores = []\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "for i in range(0,len(ftypes)):\n",
    "    X = Xer(train_data, ftypes[i])\n",
    "    y = YerCutOff(train_label, 15).reshape(255,)\n",
    "\n",
    "    scores.append(cross_validation.cross_val_score(eclf, X, y, cv=2, scoring='accuracy'))\n",
    "\n",
    "\n",
    "# for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "#     scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.703125  , 0.70866142]),\n",
       " array([0.703125 , 0.7007874]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125  , 0.70866142]),\n",
       " array([0.703125 , 0.7007874]),\n",
       " array([0.703125  , 0.70866142])]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class EnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Ensemble classifier for scikit-learn estimators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    clf : `iterable`\n",
    "      A list of scikit-learn classifier objects.\n",
    "    weights : `list` (default: `None`)\n",
    "      If `None`, the majority rule voting will be applied to the predicted class labels.\n",
    "        If a list of weights (`float` or `int`) is provided, the averaged raw probabilities (via `predict_proba`)\n",
    "        will be used to determine the most confident class label.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, clfs, weights=None):\n",
    "        self.clfs = clfs\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the scikit-learn estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "            Training data\n",
    "        y : list or numpy array, shape = [n_samples]\n",
    "            Class labels\n",
    "\n",
    "        \"\"\"\n",
    "        for clf in self.clfs:\n",
    "            clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "\n",
    "        maj : list or numpy array, shape = [n_samples]\n",
    "            Predicted class labels by majority rule\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.classes_ = np.asarray([clf.predict(X) for clf in self.clfs])\n",
    "        if self.weights:\n",
    "            avg = self.predict_proba(X)\n",
    "\n",
    "            maj = np.apply_along_axis(lambda x: max(enumerate(x), key=operator.itemgetter(1))[0], axis=1, arr=avg)\n",
    "\n",
    "        else:\n",
    "            maj = np.asarray([np.argmax(np.bincount(self.classes_[:,c])) for c in range(self.classes_.shape[1])])\n",
    "\n",
    "        return maj\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "\n",
    "        avg : list or numpy array, shape = [n_samples, n_probabilities]\n",
    "            Weighted average probability for each class per sample.\n",
    "\n",
    "        \"\"\"\n",
    "        self.probas_ = [clf.predict_proba(X) for clf in self.clfs]\n",
    "        avg = np.average(self.probas_, axis=0, weights=self.weights)\n",
    "\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CUSTOM CLASSIFIER\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class Binner(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, regressor):\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regressor.fit(X, y)\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        prediction = self.regressor.predict(X)\n",
    "        \n",
    "        if (prediction[0] > 15):\n",
    "            return np.asarray([1])\n",
    "        else:\n",
    "            return np.asarray([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "# rdc.fit(X,y)\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "bnr = Binner(rdc)\n",
    "bnr.fit(X,y)\n",
    "a = bnr.predict(X[0:1,:])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-de36b9e45e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m pipeline = Pipeline([\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'regr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     ('binner', binner)])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binner' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('regr', RandomForestRegressor(random_state=0, max_features=None)),\n",
    "    ('binner', binner)])\n",
    "    \n",
    "def binner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-c4406b5af5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, X, y, classifier)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0;31m# the test split can be too big because we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "bnr = Binner(rdc)\n",
    "score = cross_validation.cross_val_score(bnr, X, y, cv=2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_leaf': [50, 51], 'n_estimators': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ RANDOM FOREST FEATURE SELECTION #############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "# rdc = RandomForestRegressor(max_depth=2, random_state=0)#,max_features=None)\n",
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "\n",
    "# clf.fit(X, y)\n",
    "\n",
    "n_estimators = list(range(500,501))\n",
    "max_features = [\"auto\",\"sqrt\",\"log2\",0.2,0.4,0.6,0.8,None]\n",
    "min_sample_leaf = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "max_depth = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rdc, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlJmQyVWUe7gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde31df6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lizz = train_label[:,9:10].tolist()\n",
    "lizzn = []\n",
    "for i in range(0,len(lizz)):\n",
    "    lizzn.append(lizz[i][0])\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "Counter(lizzn)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels, values = zip(*Counter(lizzn).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.156e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.078e-03, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=1.010e-03, previous alpha=1.009e-03, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(255, 0), dtype=float64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "rlasso = RandomizedLasso()\n",
    "rlasso.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.075, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.02 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.01 , 0.005, 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.03 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.015, 0.   , 0.   , 0.   , 0.   , 0.01 , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.04 , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   ,\n",
       "       0.015, 0.   , 0.   , 0.   , 0.035, 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.03 ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.005, 0.   , 0.035, 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlasso.scores_[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1693)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xla = np.zeros((255, 1))\n",
    "\n",
    "for i in range(0,len(rlasso.scores_)):\n",
    "    if(rlasso.scores_[i] != 0):\n",
    "        Xla = np.hstack((Xla, X[:,i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xla = np.delete(Xla, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVC #############################\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "# parameters = {}\n",
    "\n",
    "# grid = GridSearchCV(regr, parameters, cv=2, scoring='explained_variance')\n",
    "# grid.fit(X, y)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "X = sel.fit_transform(X)\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':list([0.001,0.01,0.1,1,2,3,4,5,6,7,8,10])}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.76863, std: 0.01870, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: 0.75294, std: 0.01864, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: 0.82353, std: 0.07382, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: 0.72157, std: 0.01286, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.03042, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: 0.77255, std: 0.01479, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.01473, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: 0.74118, std: 0.02251, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: 0.69020, std: 0.01839, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 4, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 4, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 4, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 4, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 5, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 5, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 5, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 5, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 6, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 6, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 7, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 7, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 8, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 8, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: 0.65882, std: 0.01310, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n",
    "# grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.82      0.87       228\n",
      "        1.0       0.20      0.37      0.26        27\n",
      "\n",
      "avg / total       0.84      0.78      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xla)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 305)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(1.05))\n",
    "Xsel = sel.fit_transform(X)\n",
    "Xsel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xsel, y)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.81      0.86       230\n",
      "        1.0       0.17      0.36      0.23        25\n",
      "\n",
      "avg / total       0.85      0.77      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xsel)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liznb.index(max(liznb))\n",
    "max(liznb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_new = SelectKBest(chi2, k=100).fit_transform(X, y)\n",
    "# X_new.shape\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -48.36076, std: 4.91629, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: -48.48363, std: 5.11873, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: -48.47340, std: 5.10615, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: -48.48446, std: 5.11947, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: -48.30797, std: 4.56934, params: {'C': 0.005, 'kernel': 'linear'},\n",
       " mean: -48.47711, std: 5.11448, params: {'C': 0.005, 'kernel': 'rbf'},\n",
       " mean: -48.42917, std: 5.05056, params: {'C': 0.005, 'kernel': 'poly'},\n",
       " mean: -48.48173, std: 5.11783, params: {'C': 0.005, 'kernel': 'sigmoid'},\n",
       " mean: -48.84453, std: 3.90861, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: -48.46927, std: 5.10906, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: -48.36964, std: 4.99038, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: -48.47940, std: 5.11517, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: -55.87142, std: 2.88155, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: -48.33791, std: 5.02517, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: -48.36671, std: 4.72774, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: -48.32661, std: 4.86574, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: -86.93398, std: 13.02905, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: -48.09353, std: 4.93810, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: -49.11536, std: 3.98500, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: -49.10748, std: 3.86566, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: -102.49815, std: 15.76878, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: -48.76249, std: 5.03816, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: -48.99617, std: 4.14751, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: -50.06255, std: 4.14031, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: -112.84593, std: 15.88954, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: -49.93296, std: 4.56211, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: -49.04618, std: 4.33958, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: -51.04125, std: 4.20844, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: -139.56998, std: 35.20001, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: -53.95925, std: 3.78778, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: -50.51646, std: 3.49427, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: -57.70473, std: 1.94329, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVR #############################\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = Yer(train_label, 10).reshape(train_label.shape[0],)\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "c_range = [0.001,0.005,0.01,0.1,1,2,3,10]\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svr, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-48.09352610843258"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "import xml\n",
    "import xml.dom.minidom\n",
    "\n",
    "conn = sql.connect('phonedata.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "lizt = []\n",
    "gpsLookup = (1899, \"gps\")\n",
    "#for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "    \n",
    "#     print row[2]\n",
    "    lizt.append(row[2])\n",
    "    \n",
    "    \n",
    "#number of different places visited by the user\n",
    "def numDiff(lizt):\n",
    "    sum = 0\n",
    "    for i in range(0, len(lizt)):\n",
    "        a = lizt[i]\n",
    "        xmldoc = xml.dom.minidom.parseString(a)\n",
    "        kml = xmldoc.getElementsByTagName(\"kml\")[0]\n",
    "        document = kml.getElementsByTagName(\"Document\")[0]\n",
    "        placemarks = document.getElementsByTagName(\"Placemark\")\n",
    "        \n",
    "        for placemark in placemarks:\n",
    "            desc = placemark.getElementsByTagName(\"description\")[0].firstChild.data\n",
    "            sum = sum + 1\n",
    "            \n",
    "            #print desc\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "numDiff(lizt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Featurizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-deb9528a21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'./datafor19:36'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/DP\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"1899\"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\"gps\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Featurizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
