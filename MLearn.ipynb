{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3 - Write Test Set to Disk and Use At the END for test(#nosnoop)\n",
    "\n",
    "# Write to Disk\n",
    "# df = pd.DataFrame(test_data)\n",
    "# df.to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## PREPROCESSING\n",
    "\n",
    "## Cut Points and lengths\n",
    "\n",
    "# format = [startpoint, endpoint, feature count]\n",
    "contactsStartEnd = [0,1,1]\n",
    "twitterStartEnd = [1,5,4]\n",
    "textStartEnd = [5,78,73]\n",
    "callStartEnd = [78,92,14]\n",
    "instagramStartEnd = [92,110,18]\n",
    "gpsStartEnd = [110,115,5]\n",
    "audioStartEnd = [115,1698,1583]\n",
    "labelStartEnd = [1698,1708,10]\n",
    "allFeaturesStartEnd = [contactsStartEnd[0], audioStartEnd[1], 1698]\n",
    "\n",
    "\n",
    "## Below function takes mtr, returns specified modality\n",
    "\n",
    "# \"con\" contacts / \"tw\" twitter / \"txt\" text / \"call\" / \n",
    "# \"ig\" instagram / \"gps\" / au\" audio / \"label\" / \"all\" big matrix\n",
    "# \"label10cutoff\"\n",
    "\n",
    "\n",
    "# X is big matrix, ftype is filetype, labeltype can be \"continuous\", \"cutoffunbalanced\", and \"cutoffbalanced\"\n",
    "\n",
    "# returns list of two items, training data and training label\n",
    "\n",
    "# eg:\n",
    "# data, label = PPer(train_data, \"au\", \"cutoffbalanced\")\n",
    "def PPer(X, ftype, labeltype):\n",
    "    # cutoff can be varied\n",
    "    PHQ9CUTOFF = 15\n",
    "    if(ftype == \"label\"):\n",
    "        nanfull = X[:,labelStartEnd[0]:labelStartEnd[1]]\n",
    "        return nanfull\n",
    "    if(ftype == \"all\"):\n",
    "        startend = allFeaturesStartEnd\n",
    "    if(ftype == \"au\"):\n",
    "        startend = audioStartEnd\n",
    "    if(ftype == \"ig\"):\n",
    "        startend = instagramStartEnd\n",
    "    if(ftype == \"txt\"):\n",
    "        startend = textStartEnd\n",
    "    if(ftype == \"con\"):\n",
    "        startend = contactsStartEnd\n",
    "    if(ftype == \"tw\"):\n",
    "        startend = twitterStartEnd\n",
    "    if(ftype == \"call\"):\n",
    "        startend = callStartEnd\n",
    "    if(ftype == \"gps\"):\n",
    "        startend = gpsStartEnd\n",
    "    nanfull = X[:,startend[0]:startend[1]] # carve out modality from matrix\n",
    "    dataandlabel = np.hstack((nanfull, PPer(X, \"label\", \"continuous\"))) # glue data and label\n",
    "    nanless = dataandlabel[~np.isnan(dataandlabel).any(axis=1)] # remove any entry with NaN\n",
    "    if(labeltype == \"continuous\"): # normalize, return all phq answers + phq9 sum as label\n",
    "        data = nanless[:,0:startend[2]]\n",
    "        label = nanless[:,nanless.shape[1]-1:nanless.shape[1]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        return [data,label]\n",
    "    if(labeltype == \"cutoffunbalanced\"): # normalize, return binary label\n",
    "        binarylabel = np.zeros((nanless.shape[0],1))\n",
    "        for i in range(0,nanless.shape[0]):\n",
    "            if(nanless[i][nanless.shape[1]-1] > PHQ9CUTOFF):\n",
    "                binarylabel[i][0] = 1\n",
    "            else:\n",
    "                binarylabel[i][0] = 0\n",
    "        data = nanless[:,0:startend[2]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        label = binarylabel\n",
    "        return [data,label]\n",
    "    if(labeltype == \"cutoffbalanced\"):\n",
    "        data, label = PPer(X, ftype, \"cutoffunbalanced\")\n",
    "        nanless =  np.hstack((data, label))\n",
    "\n",
    "        # count zeros and ones in labels\n",
    "        onecounter = 0 # depressed\n",
    "        zerocounter = 0 # non depressed\n",
    "        for i in range(0,nanless.shape[0]):\n",
    "            if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                zerocounter += 1\n",
    "            else:\n",
    "                onecounter += 1\n",
    "\n",
    "        binarybalanced = nanless[0:1,:]\n",
    "        # less depressed ppl in set\n",
    "        if(zerocounter > onecounter): \n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                # add every data point with 1 label \n",
    "                if(nanless[i][nanless.shape[1]-1] == 1):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                if(onecounter == 0):\n",
    "                    break\n",
    "                # add same number of data points with 0 labels\n",
    "                if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "                    onecounter -= 1\n",
    "        # more depressed ppl in set \n",
    "        if(zerocounter < onecounter): \n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                # add every data point with 0 label \n",
    "                if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                if(zerocounter == 0):\n",
    "                    break\n",
    "                # add same number of data points with 0 labels\n",
    "                if(nanless[i][nanless.shape[1]-1] == 1):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "                    zerocounter -= 1\n",
    "\n",
    "        np.random.shuffle(binarybalanced)\n",
    "        data = binarybalanced[:,0:startend[2]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        label = binarybalanced[:,startend[2]:binarybalanced.shape[1]]\n",
    "        return [data,label]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREPROCESSING BUT WITHOUT TWITTER, INSTAGRAM AND GPS\n",
    "# (a copy of above for the most part)\n",
    "\n",
    "contactsStartEnd = [0,1,1]\n",
    "twitterStartEnd = [1,5,4] #\n",
    "textStartEnd = [5,78,73]\n",
    "callStartEnd = [78,92,14]\n",
    "instagramStartEnd = [92,110,18] #\n",
    "gpsStartEnd = [110,115,5] #\n",
    "audioStartEnd = [115,1698,1583]\n",
    "labelStartEnd = [1698,1708,10]\n",
    "allFeaturesStartEnd = [contactsStartEnd[0], audioStartEnd[1], 1698]\n",
    "\n",
    "\n",
    "\n",
    "# this is to try dropping twitter, instagram and gps\n",
    "def PPer_no_twiggps(X, ftype, labeltype):\n",
    "    # cutoff can be varied\n",
    "    PHQ9CUTOFF = 10\n",
    "    if(ftype == \"label\"):\n",
    "        nanfull = X[:,labelStartEnd[0]:labelStartEnd[1]]\n",
    "        return nanfull\n",
    "    if(ftype == \"all\"):\n",
    "        startend = allFeaturesStartEnd\n",
    "    startend = allFeaturesStartEnd\n",
    "    startend[2] = 1671\n",
    "        \n",
    "        \n",
    "        \n",
    "    nanfull = X[:,startend[0]:startend[1]] # carve out modality from matrix\n",
    "    \n",
    "    \n",
    "    one = X[:,contactsStartEnd[0]:contactsStartEnd[1]]\n",
    "    two = X[:,textStartEnd[0]:callStartEnd[1]]\n",
    "    three = X[:,audioStartEnd[0]:audioStartEnd[1]]\n",
    "    \n",
    "    nanfull = np.hstack((one, two, three))\n",
    "    \n",
    "    \n",
    "    dataandlabel = np.hstack((nanfull, PPer(X, \"label\", \"continuous\"))) # glue data and label\n",
    "    nanless = dataandlabel[~np.isnan(dataandlabel).any(axis=1)] # remove any entry with NaN\n",
    "    if(labeltype == \"continuous\"): # normalize, return all phq answers + phq9 sum as label\n",
    "        data = nanless[:,0:startend[2]]\n",
    "        label = nanless[:,nanless.shape[1]-1:nanless.shape[1]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        return [data,label]\n",
    "    if(labeltype == \"cutoffunbalanced\"): # normalize, return binary label\n",
    "        binarylabel = np.zeros((nanless.shape[0],1))\n",
    "        for i in range(0,nanless.shape[0]):\n",
    "            if(nanless[i][nanless.shape[1]-1] > PHQ9CUTOFF):\n",
    "                binarylabel[i][0] = 1\n",
    "            else:\n",
    "                binarylabel[i][0] = 0\n",
    "        data = nanless[:,0:startend[2]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        label = binarylabel\n",
    "        return [data,label]\n",
    "    if(labeltype == \"cutoffbalanced\"):\n",
    "        data, label = PPer(X, ftype, \"cutoffunbalanced\")\n",
    "        nanless =  np.hstack((data, label))\n",
    "\n",
    "        # count zeros and ones in labels\n",
    "        onecounter = 0 # depressed\n",
    "        zerocounter = 0 # non depressed\n",
    "        for i in range(0,nanless.shape[0]):\n",
    "            if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                zerocounter += 1\n",
    "            else:\n",
    "                onecounter += 1\n",
    "\n",
    "        binarybalanced = nanless[0:1,:]\n",
    "        # less depressed ppl in set\n",
    "        if(zerocounter > onecounter): \n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                # add every data point with 1 label \n",
    "                if(nanless[i][nanless.shape[1]-1] == 1):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                if(onecounter == 0):\n",
    "                    break\n",
    "                # add same number of data points with 0 labels\n",
    "                if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "                    onecounter -= 1\n",
    "        if(zerocounter < onecounter): \n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                # add every data point with 0 label \n",
    "                if(nanless[i][nanless.shape[1]-1] == 0):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "            for i in range(0,nanless.shape[0]):\n",
    "                if(zerocounter == 0):\n",
    "                    break\n",
    "                # add same number of data points with 0 labels\n",
    "                if(nanless[i][nanless.shape[1]-1] == 1):\n",
    "                    binarybalanced = np.vstack((binarybalanced, nanless[i:i+1,:]))\n",
    "                    zerocounter -= 1\n",
    "\n",
    "        np.random.shuffle(binarybalanced)\n",
    "        data = binarybalanced[:,0:startend[2]]\n",
    "        data = sklearn.preprocessing.scale(data)\n",
    "        label = binarybalanced[:,startend[2]:binarybalanced.shape[1]]\n",
    "        return [data,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LOADING DATA\n",
    "\n",
    "## 1 - Load Data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "mtr = pd.read_csv(\"mtr2.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "\n",
    "np.random.shuffle(mtr)\n",
    "\n",
    "## 2 - Split Data in Test and Train Set\n",
    "\n",
    "numofppl_index = mtr.shape[0] \n",
    "cut_index = int(mtr.shape[0] * 0.70)\n",
    "\n",
    "# Test (%15 percent of data)\n",
    "test_data = mtr[cut_index:numofppl_index,:]\n",
    "\n",
    "# Train (%85 percent of data)\n",
    "train_data = mtr[0:cut_index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 1583)\n",
      "(9, 18)\n",
      "(171, 73)\n",
      "(177, 1)\n",
      "(55, 4)\n",
      "(167, 14)\n",
      "(99, 5)\n",
      "(3, 1671)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"gps\"] # and \"all\"\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "\n",
    "    X,y = PPer(train_data, ftypes[i], \"cutoffbalanced\")\n",
    "    print(X.shape)\n",
    "    \n",
    "X,y = PPer_no_twiggps(train_data, \"all\", \"cutoffbalanced\")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: AU --------------\n",
      "0.8264462809917356\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.95      0.97        61\n",
      "        1.0       0.95      0.98      0.97        60\n",
      "\n",
      "avg / total       0.97      0.97      0.97       121\n",
      "\n",
      "[[58  3]\n",
      " [ 1 59]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: IG --------------\n",
      "0.5555555555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         4\n",
      "        1.0       0.56      1.00      0.71         5\n",
      "\n",
      "avg / total       0.31      0.56      0.40         9\n",
      "\n",
      "[[0 4]\n",
      " [0 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: TXT --------------\n",
      "0.5412844036697247\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.24      0.38        55\n",
      "        1.0       0.56      1.00      0.72        54\n",
      "\n",
      "avg / total       0.78      0.61      0.55       109\n",
      "\n",
      "[[13 42]\n",
      " [ 0 54]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: TW --------------\n",
      "0.5135135135135135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.51      1.00      0.68        19\n",
      "        1.0       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.26      0.51      0.35        37\n",
      "\n",
      "[[19  0]\n",
      " [18  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: CALL --------------\n",
      "0.5641025641025641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.29      0.40        59\n",
      "        1.0       0.54      0.86      0.67        58\n",
      "\n",
      "avg / total       0.61      0.57      0.53       117\n",
      "\n",
      "[[17 42]\n",
      " [ 8 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE: GPS --------------\n",
      "0.5070422535211268\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.53      1.00      0.69        36\n",
      "        1.0       1.00      0.09      0.16        35\n",
      "\n",
      "avg / total       0.76      0.55      0.43        71\n",
      "\n",
      "[[36  0]\n",
      " [32  3]]\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION TRAINING EXPERIMENT (not final)\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"tw\",\"call\",\"gps\"] # and \"all\"\n",
    "# X = PPer(train_data_10_bal,\"au\")\n",
    "# y = train_label_10_bal.reshape(244,)\n",
    "\n",
    "clfs = []\n",
    "rlassos = []\n",
    "masks = []\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "    \n",
    "    X,y = PPer(train_data, ftypes[i], \"cutoffbalanced\")\n",
    "    y = y.reshape(y.shape[0],)\n",
    "\n",
    "    rlasso = RandomizedLasso(alpha=0.001)\n",
    "    rlasso.fit(X, y)\n",
    "    X_lassod = rlasso.transform(X)\n",
    "    \n",
    "    masks.append(rlasso.get_support())\n",
    "    rlassos.append(rlasso)\n",
    "    \n",
    "    c_range = [0.001,0.01,0.02,0.03,0.04,0.05,0.1,1,2]\n",
    "#     parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "    parameters = {'kernel':('linear','poly'), 'C':c_range}\n",
    "\n",
    "    svc = svm.SVC()\n",
    "\n",
    "    grid = GridSearchCV(svc, parameters, cv=3, scoring='accuracy')\n",
    "    grid.fit(X_lassod, y)\n",
    "\n",
    "    clfs.append(grid.best_estimator_)\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    grid.grid_scores_\n",
    "    # grid.best_estimator_.get_params()\n",
    "    print(\"----------HERE BE: \" + ftypes[i].upper() + \" --------------\")\n",
    "    print(grid.best_score_)\n",
    "    predictions = grid.predict(X_lassod)\n",
    "    print(classification_report(y, predictions))\n",
    "    print(confusion_matrix(y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.03, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1 - Load Data \n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "mtr = pd.read_csv(\"mtr2.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "\n",
    "\n",
    "## 2 - Split Data in Test and Train Set\n",
    "\n",
    "numofppl_index = mtr.shape[0] \n",
    "cut_index = int(mtr.shape[0] * 0.85)\n",
    "\n",
    "# Test (%15 percent of data)\n",
    "test_data = mtr[cut_index:numofppl_index,:]\n",
    "\n",
    "# Train (%85 percent of data)\n",
    "train_data = mtr[0:cut_index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducd num cols: 70\n",
      "----------HERE BE TRAINING OF : AU --------------\n",
      "0.8201438848920863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.86      0.92        70\n",
      "        1.0       0.87      1.00      0.93        69\n",
      "\n",
      "avg / total       0.94      0.93      0.93       139\n",
      "\n",
      "[[60 10]\n",
      " [ 0 69]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducd num cols: 42\n",
      "----------HERE BE TRAINING OF : TXT --------------\n",
      "0.5813953488372093\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.35      0.50        65\n",
      "        1.0       0.59      0.94      0.72        64\n",
      "\n",
      "avg / total       0.72      0.64      0.61       129\n",
      "\n",
      "[[23 42]\n",
      " [ 4 60]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducd num cols: 4\n",
      "----------HERE BE TRAINING OF : TW --------------\n",
      "0.5102040816326531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        25\n",
      "        1.0       0.49      1.00      0.66        24\n",
      "\n",
      "avg / total       0.24      0.49      0.32        49\n",
      "\n",
      "[[ 0 25]\n",
      " [ 0 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducd num cols: 6\n",
      "----------HERE BE TRAINING OF : CALL --------------\n",
      "0.5407407407407407\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.13      0.23        68\n",
      "        1.0       0.52      0.97      0.68        67\n",
      "\n",
      "avg / total       0.67      0.55      0.45       135\n",
      "\n",
      "[[ 9 59]\n",
      " [ 2 65]]\n",
      "reducd num cols: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE TRAINING OF : GPS --------------\n",
      "0.5061728395061729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        40\n",
      "        1.0       0.51      1.00      0.67        41\n",
      "\n",
      "avg / total       0.26      0.51      0.34        81\n",
      "\n",
      "[[ 0 40]\n",
      " [ 0 41]]\n",
      "reducd num cols: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE TRAINING OF : IG --------------\n",
      "0.5384615384615384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         6\n",
      "        1.0       0.54      1.00      0.70         7\n",
      "\n",
      "avg / total       0.29      0.54      0.38        13\n",
      "\n",
      "[[0 6]\n",
      " [0 7]]\n",
      "reducd num cols: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE TRAINING OF : CON --------------\n",
      "0.5103448275862069\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      1.00      0.67        73\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "\n",
      "avg / total       0.25      0.50      0.34       145\n",
      "\n",
      "[[73  0]\n",
      " [72  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION FINAL TRAINING WITH BAGGING AND SVM\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"txt\",\"tw\",\"call\",\"gps\",\"ig\",\"con\"] # and \"all\"\n",
    "# ftypes = [\"txt\"] # and \"all\"\n",
    "\n",
    "# X = PPer(train_data_10_bal,\"au\")\n",
    "# y = train_label_10_bal.reshape(244,)\n",
    "\n",
    "clfs = []\n",
    "rlassos = []\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "    \n",
    "    X,y = PPer(train_data, ftypes[i], \"cutoffbalanced\")\n",
    "    y = y.reshape(y.shape[0],)\n",
    "        \n",
    "\n",
    "    rlasso = RandomizedLasso(alpha=0.001)\n",
    "    rlasso.fit(X, y)\n",
    "    X_lassod = rlasso.transform(X)\n",
    "    print(\"reducd num cols: \" + str(X_lassod.shape[1]))\n",
    "    rlassos.append(rlasso)\n",
    "    \n",
    "    \n",
    "#     c_range = [0.01,0.1,1]\n",
    "#     parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "#     parameters = {'kernel':('linear','poly'), 'C':c_range}\n",
    "\n",
    "    svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 1})\n",
    "    \n",
    "    if(ftypes[i] == \"txt\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 1.12})\n",
    "    \n",
    "    if(ftypes[i] == \"gps\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 1.2})\n",
    "\n",
    "    if(ftypes[i] == \"tw\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 1.3})\n",
    "    \n",
    "    if(ftypes[i] == \"call\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 1.13})\n",
    "    \n",
    "    if(ftypes[i] == \"au\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.01, class_weight={1: 4})\n",
    "        \n",
    "    if(ftypes[i] == \"ig\"):\n",
    "        svc = svm.SVC(kernel='linear', C=0.1, class_weight={1: 1.3})\n",
    "#     treee = tree.DecisionTreeClassifier()\n",
    "\n",
    "    \n",
    "    \n",
    "    bagging = BaggingClassifier(svc)\n",
    "\n",
    "    \n",
    "    parameters = {'max_samples':(0.6,0.7), 'max_features':(0.9,0.99), 'n_estimators':(10,20,30)}\n",
    "    if(ftypes[i] == \"con\"):\n",
    "        parameters = {'max_samples':(0.6,0.7), 'n_estimators':(10,20,30)}\n",
    "    \n",
    "\n",
    "    \n",
    "#     grid = GridSearchCV(bagging, parameters, cv=3, scoring='accuracy')\n",
    "    grid = GridSearchCV(bagging, parameters, cv=3, scoring='accuracy')\n",
    "\n",
    "    \n",
    "    \n",
    "    if(ftypes[i] != \"con\"):\n",
    "        grid.fit(X_lassod, y)\n",
    "    if(ftypes[i] == \"con\"):\n",
    "        grid.fit(X, y)\n",
    "\n",
    "\n",
    "    clfs.append(grid.best_estimator_)\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    grid.grid_scores_\n",
    "    # grid.best_estimator_.get_params()\n",
    "    print(\"----------HERE BE TRAINING OF : \" + ftypes[i].upper() + \" --------------\")\n",
    "    print(grid.best_score_)\n",
    "    predictions = grid.predict(X_lassod)\n",
    "    print(classification_report(y, predictions))\n",
    "    print(confusion_matrix(y, predictions))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     ## test\n",
    "#     Xtest,ytest = PPer(test_data, ftypes[i], \"cutoffunbalanced\")\n",
    "#     ytest = ytest.reshape(ytest.shape[0],)\n",
    "\n",
    "#     Xtest = rlasso.transform(Xtest)\n",
    "    \n",
    "    \n",
    "#     print(\"reducd num cols: \" + str(Xtest.shape[1]))\n",
    "    \n",
    "    \n",
    "#     print(\"----------HERE BE TEST OF: \" + ftypes[i].upper() + \" --------------\")\n",
    "    \n",
    "#     predictio = grid.predict(Xtest)\n",
    "#     print(classification_report(ytest, predictio))\n",
    "#     print(confusion_matrix(ytest, predictio))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 1583)\n",
      "reducd num cols: 70\n",
      "----------HERE BE TEST OF: AU --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.21      0.30        28\n",
      "        1.0       0.29      0.60      0.39        15\n",
      "\n",
      "avg / total       0.43      0.35      0.33        43\n",
      "\n",
      "[[ 6 22]\n",
      " [ 6  9]]\n",
      "(41, 73)\n",
      "reducd num cols: 42\n",
      "----------HERE BE TEST OF: TXT --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      0.12      0.19        24\n",
      "        1.0       0.36      0.71      0.48        17\n",
      "\n",
      "avg / total       0.37      0.37      0.31        41\n",
      "\n",
      "[[ 3 21]\n",
      " [ 5 12]]\n",
      "(16, 4)\n",
      "reducd num cols: 4\n",
      "----------HERE BE TEST OF: TW --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        12\n",
      "        1.0       0.25      1.00      0.40         4\n",
      "\n",
      "avg / total       0.06      0.25      0.10        16\n",
      "\n",
      "[[ 0 12]\n",
      " [ 0  4]]\n",
      "(41, 14)\n",
      "reducd num cols: 6\n",
      "----------HERE BE TEST OF: CALL --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.04      0.07        24\n",
      "        1.0       0.39      0.88      0.55        17\n",
      "\n",
      "avg / total       0.36      0.39      0.27        41\n",
      "\n",
      "[[ 1 23]\n",
      " [ 2 15]]\n",
      "(25, 5)\n",
      "reducd num cols: 5\n",
      "----------HERE BE TEST OF: GPS --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        19\n",
      "        1.0       0.24      1.00      0.39         6\n",
      "\n",
      "avg / total       0.06      0.24      0.09        25\n",
      "\n",
      "[[ 0 19]\n",
      " [ 0  6]]\n",
      "(3, 18)\n",
      "reducd num cols: 2\n",
      "----------HERE BE TEST OF: IG --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         3\n",
      "        1.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00         3\n",
      "\n",
      "[[0 3]\n",
      " [0 0]]\n",
      "reducd num cols: 1\n",
      "----------HERE BE TEST OF: CON --------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      1.00      0.77        27\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.39      0.63      0.48        43\n",
      "\n",
      "[[27  0]\n",
      " [16  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION TEST SET RESULTS\n",
    "\n",
    "ftypes = [\"au\",\"txt\",\"tw\",\"call\",\"gps\",\"ig\",\"con\"] # and \"all\"\n",
    "# ftypes = [\"txt\"] # and \"all\"\n",
    "\n",
    "# X = PPer(train_data_10_bal,\"au\")\n",
    "# y = train_label_10_bal.reshape(244,)\n",
    "\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "    \n",
    "    Xtest,ytest = PPer(test_data, ftypes[i], \"cutoffunbalanced\")\n",
    "    ytest = ytest.reshape(ytest.shape[0],)\n",
    "\n",
    "    if(ftypes[i] != \"con\"):\n",
    "        print(Xtest.shape)\n",
    "        Xtest = rlassos[i].transform(Xtest)\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"reducd num cols: \" + str(Xtest.shape[1]))\n",
    "    \n",
    "    \n",
    "    print(\"----------HERE BE TEST OF: \" + ftypes[i].upper() + \" --------------\")\n",
    "    \n",
    "    predictio = clfs[i].predict(Xtest)\n",
    "    print(classification_report(ytest, predictio))\n",
    "    print(confusion_matrix(ytest, predictio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=0.01, cache_size=200, class_weight={1: 4}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.99,\n",
       "         max_samples=0.6, n_estimators=20, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SERVER INTEGRATION\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#####################3\n",
    "#####################\n",
    "#####################3\n",
    "#####################\n",
    "#####################3\n",
    "#####################\n",
    "\n",
    "\n",
    "# This is where data is stored\n",
    "# it is a dict where every key is the ID of a user\n",
    "# The entry for each ID is another dict that looks like this\n",
    "# {'text': [], 'log': [], \"file\": [], \"calendar\": [], \"contact\":[], \"audio\": []}\n",
    "# I then add each piece of received data to the corresponding array\n",
    "receivedData = {}\n",
    "\n",
    "\n",
    "# Return a string version of whatever result we want to display\n",
    "# INPUT - ID - the id (as a string) of the requesting device\n",
    "def getClassification(ID):\n",
    "    global receivedData\n",
    "\n",
    "    userdata = receivedData[ID]\n",
    "\n",
    "    scrapetime = userdata['scrapetime']\n",
    "    \n",
    "    textp = userdata['text']\n",
    "    callp = userdata['log']\n",
    "    conp = userdata['contact']\n",
    "    audiop = userdata['audio']\n",
    "    gpsp = userdata['gps']\n",
    "#     instagramp = userdata['']\n",
    "#     instagrammediap = userdata['']\n",
    "    twitterp = ['tweets']\n",
    "    \n",
    "    \n",
    "        ### INITIALIZATION\n",
    "    \n",
    "    # call frequency\n",
    "    featureVectorCF = np.zeros((1,14))\n",
    "    # follower count\n",
    "    featureVectorFC = np.zeros((1,1))\n",
    "    # following count\n",
    "    featureVectorFC2 = np.zeros((1,1))\n",
    "    # twitter like frequency\n",
    "    featureVectorTWL = np.zeros((1,1))\n",
    "    # twitter retweet frequency\n",
    "    featureVectorTWRT = np.zeros((1,1))\n",
    "    # num of contacts\n",
    "    featureVectorNC = np.zeros((1,1))\n",
    "    # instagram follows, followed by\n",
    "    featureVectorIG1 = np.zeros((1,2))\n",
    "    # instagram filter usage freq\n",
    "    featureVectorIG2 = np.zeros((1,1))\n",
    "    # instagram filter vec: Valencia, X-Pro II, Hefe, Amaro, Rise, Willow, Crema, Inkwell\n",
    "    featureVectorIGFV = np.zeros((1,8))\n",
    "    # instagram like freq, comment freq\n",
    "    featureVectorIGLC = np.zeros((1,2))\n",
    "    # instagram post freq\n",
    "    featureVectorIG3 = np.zeros((1,1))\n",
    "    # instagram avg Hue, Saturation, Value, and total faces\n",
    "    featureVectorHSVF = np.zeros((1,4))\n",
    "    # audio features from openSMILE\n",
    "    featureVectorAUD = np.zeros((1,1583))\n",
    "    # text frequency\n",
    "    featureVectorTF = np.zeros((1,14))\n",
    "    # 45 long POS (part of speech) vector\n",
    "    POSFreqVec = np.zeros((1,45))\n",
    "    # 14 long vector, 10 day sentiment average for past 14 days\n",
    "    SentFreqVec = np.zeros((1,14))\n",
    "    # gps feature 1\n",
    "    gpsVector1 = np.zeros((1,1))\n",
    "    # gps feature 2\n",
    "    gpsVector2 = np.zeros((1,1))\n",
    "    # gps feature 3\n",
    "    gpsVector3 = np.zeros((1,1))\n",
    "    # gps feature 4\n",
    "    gpsVector4 = np.zeros((1,1))\n",
    "    # gps feature 5\n",
    "    gpsVector5 = np.zeros((1,1))\n",
    "    \n",
    "\n",
    "        ### FEATURIZATION\n",
    "    \n",
    "    f = Featurizer() \n",
    "\n",
    "    ## GPS\n",
    "    gpsVector1[0] = f.numDiff(gpsp)\n",
    "    gpsVector2[0] = f.maxDist(gpsp)\n",
    "    gpsVector3[0] = f.totDist(gpsp)\n",
    "    gpsVector4[0] = f.activeFreq(gpsp)\n",
    "    gpsVector5[0] = f.distanceRan(gpsp)\n",
    "    \n",
    "    ## CALL\n",
    "    featureVectorCF[i] = f.callFreqVec14(callp, scrapetime)\n",
    "    \n",
    "    ## SMS\n",
    "    POSFreqVec[i] = f.POSTagger(textp)\n",
    "    SentFreqVec[i] = f.SentAnalysis(textp, scrapetime)\n",
    "    featureVectorTF[i] = f.textFreqVec14(textp, scrapetime)\n",
    "    \n",
    "    ## TWITTER\n",
    "    featureVectorFC[i] = f.followerCount(twitterp)\n",
    "    featureVectorFC2[i] = f.followingCount(twitterp)\n",
    "    featureVectorTWL[i] = f.twitterLikeFreq(twitterp, scrapetime)\n",
    "    featureVectorTWRT[i] = f.twitterRetweetFreq(twitterp, scrapetime)\n",
    "            \n",
    "    ## CONTACTS\n",
    "    featureVectorNC[i] = f.numOfContacts(conp)\n",
    "    \n",
    "    ## CURRENTLY SERVER DOESNT SUPPORT INSTAGRAM!\n",
    "#     ## INSTAGRAM\n",
    "#     featureVectorIG1[i] = f.instagramThings(instagramp)\n",
    "#     ## INSTAGRAM MEDIA\n",
    "#     featureVectorIG2[i] = f.instagramFilterFreq(a6, self.list_of_times[i])\n",
    "#     featureVectorIGFV[i] = f.instagramFilterVector(a6, self.list_of_times[i])\n",
    "#     featureVectorIGLC[i] = f.instagramLikeComFreq(a6, self.list_of_times[i])\n",
    "#     featureVectorIG3[i] = f.instagramPostFreq(a6, self.list_of_times[i])\n",
    "#     featureVectorHSVF[i] = f.averageHSVF(a6, self.list_of_times[i])\n",
    "            \n",
    "    ## AUDIO\n",
    "    featureVectorAUD[i] = f.voiceFeaturizer(audiop)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### VECTORIZATION\n",
    "    \n",
    "    GPSMtr = np.hstack((gpsVector1, \n",
    "                            gpsVector2, \n",
    "                            gpsVector3,\n",
    "                            gpsVector4, \n",
    "                            gpsVector5))\n",
    "    CallMtr = featureVectorCF        \n",
    "    TextMtr = np.hstack((featureVectorTF, \n",
    "                                    SentFreqVec, \n",
    "                                    POSFreqVec))         \n",
    "    TwitterMtr = np.hstack((featureVectorFC, \n",
    "                                     featureVectorFC2, \n",
    "                                     featureVectorTWL, \n",
    "                                     featureVectorTWRT))        \n",
    "    ContactsMtr = featureVectorNC        \n",
    "    IGMtr = np.hstack((featureVectorIG1, \n",
    "                                     featureVectorIG2, \n",
    "                                     featureVectorIGFV,\n",
    "                                     featureVectorIGLC, \n",
    "                                     featureVectorIG3, \n",
    "                                     featureVectorHSVF))        \n",
    "    AudioMtr = featureVectorAUD\n",
    "\n",
    "    personvector = np.hstack((ContactsMtr, \n",
    "                            TwitterMtr, \n",
    "                            TextMtr, \n",
    "                            CallMtr, \n",
    "                            IGMtr,\n",
    "                            GPSMtr,\n",
    "                            AudioMtr))\n",
    "    \n",
    "    \n",
    "    ## run this, or modalities thru classifiers\n",
    "    personvector\n",
    "    \n",
    "    \n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\", \"gps\"] \n",
    "    \n",
    "    regressors = []\n",
    "    rlassos = []\n",
    "\n",
    "    for i in range(0,len(ftypes)):\n",
    "        \n",
    "        # load regression models from disk\n",
    "        regressor = pickle.load(open(\"./persistentmodels/\" +  str(ftypes[i]) + \"_regressor.p\", \"rb\" ))\n",
    "        rlasso = pickle.load(open(\"./persistentmodels/\" +  str(ftypes[i]) + \"_rlassomask.p\", \"rb\" ))\n",
    "        \n",
    "        # put em in a list\n",
    "        regressors.append(regressor)\n",
    "        rlassos.append(rlasso)\n",
    "\n",
    "        \n",
    "    # actual predicting\n",
    "    AudioMtr = rlassos[0].transform(AudioMtr)\n",
    "    audiopred = regressors[0].predict(AudioMtr)[0]\n",
    "    \n",
    "    TextMtr = rlassos[0].transform(TextMtr)\n",
    "    txtpred = regressors[0].predict(TextMtr)[0]\n",
    "    \n",
    "    ContactsMtr = rlassos[0].transform(ContactsMtr)\n",
    "    conpred = regressors[0].predict(ContactsMtr)[0]\n",
    "    \n",
    "    TwitterMtr = rlassos[0].transform(TwitterMtr)\n",
    "    twpred = regressors[0].predict(TwitterMtr)[0]\n",
    "    \n",
    "    CallMtr = rlassos[0].transform(CallMtr)\n",
    "    callpred = regressors[0].predict(CallMtr)[0]\n",
    "    \n",
    "    GPSMtr = rlassos[0].transform(GPSMtr)\n",
    "    gpspred = regressors[0].predict(GPSMtr)[0]\n",
    "    \n",
    "    \n",
    "    # we opted to equally weigh all regression results, \n",
    "    # instead of using the classifiers we trained through an ensemble\n",
    "    \n",
    "    # this is because our classifiers sucked on the testing set\n",
    "    # but our regressors were great on the testing set\n",
    "    # see MQP paper for more info.\n",
    "    \n",
    "    predictedPHQ9 = (audiopred+txtpred+conpred+twpred+callpred+gpspred)/6\n",
    "\n",
    "    return predictedPHQ9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zes = []\n",
    "# zes.append(5).append(6)\n",
    "zes.append(5)\n",
    "zes.append(5)\n",
    "zes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = {'text': [3], 'log': [], \"file\": [], \"calendar\": [], \"contact\":[]}\n",
    "rec['log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method SelectorMixin.get_support of RandomizedLasso(alpha=0.001, eps=2.220446049250313e-16, fit_intercept=True,\n",
      "        max_iter=500, memory=None, n_jobs=1, n_resampling=200,\n",
      "        normalize=True, pre_dispatch='3*n_jobs', precompute='auto',\n",
      "        random_state=None, sample_fraction=0.75, scaling=0.5,\n",
      "        selection_threshold=0.25, verbose=False)>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.82      0.85       114\n",
      "        1.0       0.84      0.89      0.86       115\n",
      "\n",
      "avg / total       0.86      0.86      0.86       229\n",
      "\n",
      "[[ 94  20]\n",
      " [ 13 102]]\n"
     ]
    }
   ],
   "source": [
    "# AUDIO ONLY CLASSIFICATION TRAIN\n",
    "\n",
    "\n",
    "X,y = PPer(train_data, \"au\", \"cutoffbalanced\")\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.001)\n",
    "rlasso.fit(X, y)\n",
    "X_lassod = rlasso.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "c_range = list(range(1, 15))\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=3, scoring='accuracy')\n",
    "grid.fit(X_lassod, y)\n",
    "\n",
    "\n",
    "predictions = grid.predict(X_lassod)\n",
    "print(classification_report(y, predictions))\n",
    "print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(rlasso.get_support())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : AU --------------\n",
      "5.744562646538029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : IG --------------\n",
      "5.196152422706632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : TXT --------------\n",
      "6.855654600401044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : CON --------------\n",
      "7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : TW --------------\n",
      "6.4031242374328485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : CALL --------------\n",
      "6.928203230275509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE : GPS --------------\n",
      "6.928203230275509\n"
     ]
    }
   ],
   "source": [
    "# REGRESSION FINAL TRAINING\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\", \"gps\"] #and \"all\"\n",
    "# X = PPer(train_data_10_bal,\"au\")\n",
    "# y = train_label_10_bal.reshape(244,)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "clfsreg = []\n",
    "rlassosreg = []\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "\n",
    "    X,y = PPer(train_data, ftypes[i], \"continuous\")\n",
    "    y = y.reshape(y.shape[0],)\n",
    "\n",
    "    # from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "    rlasso = RandomizedLasso(alpha=0.001)\n",
    "    rlasso.fit(X, y)\n",
    "    X_lassod = rlasso.transform(X)\n",
    "\n",
    "    rlassosreg.append(rlasso)\n",
    "\n",
    "    c_range = list(range(1, \n",
    "                         15))\n",
    "    parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "    svr = SVR()\n",
    "\n",
    "    grid = GridSearchCV(svr, parameters, cv=4, scoring='neg_mean_squared_error')\n",
    "    grid.fit(X_lassod, y)\n",
    "    \n",
    "    clfsreg.append(grid.best_estimator_)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    grid.grid_scores_\n",
    "    # grid.best_estimator_.get_params()\n",
    "    predictions = grid.predict(X_lassod)\n",
    "\n",
    "    \n",
    "    print(\"----------HERE BE : \" + ftypes[i].upper() + \" --------------\")\n",
    "\n",
    "    \n",
    "    import math\n",
    "    print(math.sqrt(int(grid.best_score_*-1)))\n",
    "    # print(classification_report(y, predictions))\n",
    "    # print(confusion_matrix(y, predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------HERE BE TEST OF : AU --------------\n",
      "5.656854249492381\n",
      "----------HERE BE TEST OF : IG --------------\n",
      "1.7320508075688772\n",
      "----------HERE BE TEST OF : TXT --------------\n",
      "5.477225575051661\n",
      "----------HERE BE TEST OF : CON --------------\n",
      "5.291502622129181\n",
      "----------HERE BE TEST OF : TW --------------\n",
      "4.242640687119285\n",
      "----------HERE BE TEST OF : CALL --------------\n",
      "5.385164807134504\n",
      "----------HERE BE TEST OF : GPS --------------\n",
      "6.708203932499369\n"
     ]
    }
   ],
   "source": [
    "# REGRESSION TEST SET RESULTS\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\", \"gps\"] #and \"all\"\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "    \n",
    "    X,y = PPer(test_data, ftypes[i], \"continuous\")\n",
    "    y = y.reshape(y.shape[0],)\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "    X_lassod = rlassosreg[i].transform(X)\n",
    "\n",
    "\n",
    "    scorz = cross_val_score(clfsreg[i], X_lassod, y, scoring='neg_mean_squared_error') \n",
    "    \n",
    "    print(\"----------HERE BE TEST OF : \" + ftypes[i].upper() + \" --------------\")\n",
    "\n",
    "    print(math.sqrt(int(max(scorz)*-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.907271133031658"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfsreg[6].predict(X_lassod[0:1,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=5, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='sigmoid', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfsreg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PERSISTENCE\n",
    "import _pickle as pickle\n",
    "\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\", \"gps\"] #and \"all\"\n",
    "\n",
    "for i in range(0,len(ftypes)):\n",
    "\n",
    "    pickle.dump(clfsreg[i], open( \"./persistentmodels/\" +  str(ftypes[i]) + \"_regressor.p\" , \"wb\" ))\n",
    "    pickle.dump(rlassosreg[i], open(\"./persistentmodels/\" + str(ftypes[i]) + \"_rlassomask.p\" , \"wb\" ))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-48.753051834396956"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "# n gives nth phq answer\n",
    "# 10 gives sum of all phqs\n",
    "def Yer(y, n):\n",
    "    return y[:,n-1:n]\n",
    "\n",
    "\n",
    "contactsStartEnd = [0,1]\n",
    "twitterStartEnd = [1,5]\n",
    "textStartEnd = [5,78]\n",
    "callStartEnd = [78,92]\n",
    "instagramStartEnd = [92,110]\n",
    "# gpsStartEnd = [110,113]\n",
    "\n",
    "audioStartEnd = [110,1693]\n",
    "\n",
    "allStartEnd = [contactsStartEnd[0], audioStartEnd[1]]\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "\n",
    "# ftype = \"au\" audio / \"ig\" instagram / \"txt\" text / \"con\" contacts / \"tw\" twitter / \"call\" call\n",
    "# \"all\" = big matrix\n",
    "def Xer(X, ftype):\n",
    "    if(ftype == \"au\"):\n",
    "        return X[:,audioStartEnd[0]:audioStartEnd[1]]\n",
    "    if(ftype == \"ig\"):\n",
    "        return X[:,instagramStartEnd[0]:instagramStartEnd[1]]\n",
    "    if(ftype == \"txt\"):\n",
    "        return X[:,textStartEnd[0]:textStartEnd[1]]\n",
    "    if(ftype == \"con\"):\n",
    "        return X[:,contactsStartEnd[0]:contactsStartEnd[1]]\n",
    "    if(ftype == \"tw\"):\n",
    "        return X[:,twitterStartEnd[0]:twitterStartEnd[1]]\n",
    "    if(ftype == \"call\"):\n",
    "        return X[:,callStartEnd[0]:callStartEnd[1]]\n",
    "#     if(ftype == \"gps\"):\n",
    "#         return X[:,gpsStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"all\"):\n",
    "        return X[:,allStartEnd[0]:allStartEnd[1]]\n",
    "    if(ftype == \"audioless\"):\n",
    "        return X[:,allStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"gpsless\"):\n",
    "        return np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## PREPROCESSING\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "mtr = pd.read_csv(\"mtr1.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "#mtr.shape\n",
    "\n",
    "## PREPROCESSING\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# shuffle row-wise\n",
    "np.random.shuffle(mtr)\n",
    "\n",
    "data = mtr[:,allStartEnd[0]:allStartEnd[1]]\n",
    "\n",
    "labels = mtr[:,1693:1704]\n",
    "\n",
    "\n",
    "\n",
    "# replace missing values with mean of their corresponding features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# If NaNs should be dropped instead:\n",
    "# mtr = mtr[~np.isnan(mtr).any(axis=1)]\n",
    "\n",
    "# normalize data (features now have gauss dist., 0 mean and unit variance)\n",
    "data = sklearn.preprocessing.scale(data)\n",
    "\n",
    "\n",
    "# THIS IS AN ALTERNATIVE TO 0 MEAN UNIT VARIANCE NORMALIZATION\n",
    "# do this to scale features to range 0-1\n",
    "# this must be done if a chi^2 is being performed\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data = min_max_scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "# n gives nth phq answer\n",
    "# 10 gives sum of all phqs\n",
    "def Yer(y, n):\n",
    "    return y[:,n-1:n]\n",
    "\n",
    "\n",
    "contactsStartEnd = [0,1]\n",
    "twitterStartEnd = [1,5]\n",
    "textStartEnd = [5,78]\n",
    "callStartEnd = [78,92]\n",
    "instagramStartEnd = [92,110]\n",
    "# gpsStartEnd = [110,113]\n",
    "\n",
    "audioStartEnd = [110,1693]\n",
    "\n",
    "allStartEnd = [contactsStartEnd[0], audioStartEnd[1]]\n",
    "\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "\n",
    "# ftype = \"au\" audio / \"ig\" instagram / \"txt\" text / \"con\" contacts / \"tw\" twitter / \"call\" call\n",
    "# \"all\" = big matrix\n",
    "def Xer(X, ftype):\n",
    "    if(ftype == \"au\"):\n",
    "        return X[:,audioStartEnd[0]:audioStartEnd[1]]\n",
    "    if(ftype == \"ig\"):\n",
    "        return X[:,instagramStartEnd[0]:instagramStartEnd[1]]\n",
    "    if(ftype == \"txt\"):\n",
    "        return X[:,textStartEnd[0]:textStartEnd[1]]\n",
    "    if(ftype == \"con\"):\n",
    "        return X[:,contactsStartEnd[0]:contactsStartEnd[1]]\n",
    "    if(ftype == \"tw\"):\n",
    "        return X[:,twitterStartEnd[0]:twitterStartEnd[1]]\n",
    "    if(ftype == \"call\"):\n",
    "        return X[:,callStartEnd[0]:callStartEnd[1]]\n",
    "#     if(ftype == \"gps\"):\n",
    "#         return X[:,gpsStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"all\"):\n",
    "        return X[:,allStartEnd[0]:allStartEnd[1]]\n",
    "    if(ftype == \"audioless\"):\n",
    "        return X[:,allStartEnd[0]:gpsStartEnd[1]]\n",
    "    if(ftype == \"gpsless\"):\n",
    "        return np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## PREPROCESSING\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "mtr = pd.read_csv(\"mtr1.csv\").values\n",
    "mtr = np.delete(mtr, 0, axis = 1) # because dataframe adds a rogue column\n",
    "#mtr.shape\n",
    "\n",
    "## PREPROCESSING\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# shuffle row-wise\n",
    "np.random.shuffle(mtr)\n",
    "\n",
    "data = mtr[:,allStartEnd[0]:allStartEnd[1]]\n",
    "# data = np.hstack((X[:,allStartEnd[0]:instagramStartEnd[1]], X[:,audioStartEnd[0]:audioStartEnd[1]]))\n",
    "\n",
    "\n",
    "labels = mtr[:,1693:1704]\n",
    "\n",
    "\n",
    "\n",
    "# replace missing values with mean of their corresponding features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# If NaNs should be dropped instead:\n",
    "# mtr = mtr[~np.isnan(mtr).any(axis=1)]\n",
    "\n",
    "# normalize data (features now have gauss dist., 0 mean and unit variance)\n",
    "data = sklearn.preprocessing.scale(data)\n",
    "\n",
    "\n",
    "# THIS IS AN ALTERNATIVE TO 0 MEAN UNIT VARIANCE NORMALIZATION\n",
    "# do this to scale features to range 0-1\n",
    "# this must be done if a chi^2 is being performed\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data = min_max_scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATA SPLIT (#nosnooping)\n",
    "\n",
    "# TEST DATA (%15 percent of data)\n",
    "numofppl_index = mtr.shape[0] - 1\n",
    "cut_index = int(mtr.shape[0] * 0.85)\n",
    "\n",
    "test_label = labels[cut_index:numofppl_index,:]\n",
    "test_data = data[cut_index:numofppl_index,:]\n",
    "\n",
    "# TRAINING AND VALIDATION DATA (%85 percent of data)\n",
    "\n",
    "train_label = labels[0:cut_index,:]\n",
    "train_data = data[0:cut_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 10)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "\n",
    "# balancing for 15\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,1:2]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,1:2]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,1:2] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,1:2]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,1:2] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,1:2]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "np.random.shuffle(train_label_15_bal)\n",
    "np.random.shuffle(train_data_15_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "# balancing for 20\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,2:3]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,2:3]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,2:3] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,2:3]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,2:3] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,2:3]))\n",
    "        \n",
    "\n",
    "train_data_15_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_15_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "np.random.shuffle(train_label_15_bal)\n",
    "np.random.shuffle(train_data_15_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "# balancing for 10\n",
    "\n",
    "onecounter = 0\n",
    "onesdata = train_data[0:1,:]\n",
    "oneslabel = train_label[0:1,0:1]\n",
    "zerodata = train_data[1:2,:]\n",
    "zerolabel = train_label[1:2,0:1]\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(train_label[i:i+1,0:1] == 1):\n",
    "        onecounter += 1\n",
    "        onesdata = np.vstack((onesdata, train_data[i:i+1,:]))\n",
    "        oneslabel = np.vstack((oneslabel, train_label[i:i+1,0:1]))\n",
    "\n",
    "for i in range(0,train_label.shape[0]):\n",
    "    if(onecounter == 0):\n",
    "        break\n",
    "    if(train_label[i:i+1,0:1] == 0):\n",
    "        onecounter -= 1\n",
    "        zerodata = np.vstack((zerodata, train_data[i:i+1,:]))\n",
    "        zerolabel = np.vstack((zerolabel, train_label[i:i+1,0:1]))\n",
    "        \n",
    "\n",
    "train_data_10_bal = np.vstack((onesdata, zerodata))\n",
    "train_label_10_bal = np.vstack((oneslabel, zerolabel))\n",
    "\n",
    "tempmtr =  np.hstack((train_data_10_bal, train_label_10_bal))\n",
    "np.random.shuffle(tempmtr)\n",
    "\n",
    "train_data_10_bal = tempmtr[:,0:1693]\n",
    "train_label_10_bal = tempmtr[:,1693:1694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 1693)"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_10_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD PREPROCESSING (DEPRECATED)\n",
    "\n",
    "\n",
    "def cutoff(train_label):\n",
    "\n",
    "    phqcutoffs = [10,15,20]\n",
    "\n",
    "    for j in range(0,len(phqcutoffs)):\n",
    "        for i in range(0,train_label[:,9:10].shape[0]):\n",
    "            if(train_label[i][9] > phqcutoffs[j]):\n",
    "                train_label[i][j] = 1\n",
    "            else:\n",
    "                train_label[i][j] = 0\n",
    "               \n",
    "    train_label_x = train_label\n",
    "    \n",
    "    return train_label_x               \n",
    "\n",
    "def YerCutOff(y, cutoff):\n",
    "    if (cutoff == 10):\n",
    "        return y[:,0:1]\n",
    "    if (cutoff == 15):\n",
    "        return y[:,1:2]\n",
    "    if (cutoff == 20):\n",
    "        return y[:,2:3]\n",
    "    \n",
    "# train_label = cutoff(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CLASSIFICATION TRAINING FOR CUTOFF 15 AND 20\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "#             X = Xer(train_data, ftypes[i])\n",
    "#             y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            X = Xer(train_data_15_bal, ftypes[i])\n",
    "            y = train_label_15_bal.reshape(54,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            svc = svm.SVC()\n",
    "\n",
    "            grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au   ig       txt       con   tw      call       all\n",
       "0  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519\n",
       "1  0.444444  0.5  0.574074  0.481481  0.5  0.611111  0.518519"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 1693)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_15_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 73)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Xer(train_data_10_bal,\"txt\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.91      0.82       122\n",
      "        1.0       0.89      0.70      0.78       122\n",
      "\n",
      "avg / total       0.82      0.80      0.80       244\n",
      "\n",
      "[[111  11]\n",
      " [ 37  85]]\n"
     ]
    }
   ],
   "source": [
    "## AUDIO CLASSIFICATION TRAINING SVM + RLASSO\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "X = Xer(train_data_10_bal,\"au\")\n",
    "y = train_label_10_bal.reshape(244,)\n",
    "\n",
    "# au gives 85\n",
    "\n",
    "# from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.001)\n",
    "rlasso.fit(X, y)\n",
    "X_lassod = rlasso.transform(X)\n",
    "X_lassod\n",
    "\n",
    "c_range = list(range(1, 15))\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=3, scoring='accuracy')\n",
    "grid.fit(X_lassod, y)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "grid.best_score_\n",
    "predictions = grid.predict(X_lassod)\n",
    "print(classification_report(y, predictions))\n",
    "print(confusion_matrix(y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  17],\n",
       "       [ 40,  82]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 91)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()\n",
    "X_lassod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.85      0.79       128\n",
      "        1.0       0.83      0.70      0.76       128\n",
      "\n",
      "avg / total       0.78      0.78      0.78       256\n",
      "\n",
      "[[109  19]\n",
      " [ 38  90]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## AUDIO CLASSIFICATION TRAINING RANDOM FORREST + RLASSO\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "results = np.zeros((2,7))\n",
    "paras = []\n",
    "\n",
    "def HyperTunerSVM(trainX,trainy):\n",
    "    \n",
    "    ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"] # and \"all\"\n",
    "    cutoffs = [15,20]\n",
    "    for i in range(0,len(ftypes)):\n",
    "        for j in range(0,len(cutoffs)):\n",
    "            \n",
    "            X = Xer(train_data, ftypes[i])\n",
    "            y = YerCutOff(train_label, cutoffs[j]).reshape(255,)\n",
    "            \n",
    "            c_range = list(range(1, 10))\n",
    "            parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "            \n",
    "            min_sample_leaf = list(range(50,52))\n",
    "            parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "            \n",
    "            rfc = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "\n",
    "            grid = GridSearchCV(rfc, parameters, cv=2, scoring='accuracy')\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            results[j][i] = grid.best_score_\n",
    "            paras.append(grid.best_estimator_.get_params())\n",
    "\n",
    "\n",
    "            \n",
    "HyperTunerSVM(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>au</th>\n",
       "      <th>ig</th>\n",
       "      <th>txt</th>\n",
       "      <th>con</th>\n",
       "      <th>tw</th>\n",
       "      <th>call</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.898039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         au        ig       txt       con        tw      call       all\n",
       "0  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882  0.705882\n",
       "1  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039  0.898039"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=[\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 50,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90 (+/- 0.00) [randyforst]\n",
      "Accuracy: 0.90 (+/- 0.00) [svm classifier]\n",
      "Accuracy: 0.90 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(max_depth=2, random_state=0, n_estimators=500, max_features=None, min_samples_leaf=50)\n",
    "clf2 = svm.SVC(C=2, kernel=\"rbf\", probability=True)\n",
    "\n",
    "np.random.seed(123)\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2], weights=[1,1])\n",
    "\n",
    "X = Xer(train_data, ftypes[i])\n",
    "y = YerCutOff(train_label, 20).reshape(255,)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, eclf], ['randyforst', 'svm classifier', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      1.00      0.95       229\n",
      "        1.0       0.00      0.00      0.00        26\n",
      "\n",
      "avg / total       0.81      0.90      0.85       255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "eclf.fit(X, y)\n",
    "\n",
    "# grid.grid_scores_\n",
    "# grid.best_estimator_.get_params()\n",
    "# grid.best_score_\n",
    "predictions = eclf.predict(X)\n",
    "print(classification_report(y, predictions))\n",
    "# print(confusion_matrix(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 15 CUTOFF WITH CUSTOM ENSEMBLE EXPERIMENTAL \n",
    "\n",
    "clf1 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #au\n",
    "clf2 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) #ig\n",
    "clf3 = svm.SVC(C=1, kernel=\"sigmoid\" , probability=True) #txt\n",
    "clf4 = svm.SVC(C=2, kernel=\"rbf\" , probability=True) # con\n",
    "clf5 = svm.SVC(C=1, kernel=\"rbf\" , probability=True) # tw\n",
    "clf6 = svm.SVC(C=1, kernel=\"rbf\", probability=True) # call\n",
    "\n",
    "\n",
    "eclf = EnsembleClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6], weights=[1,1,1,1,1,1])\n",
    "\n",
    "scores = []\n",
    "\n",
    "ftypes = [\"au\",\"ig\",\"txt\",\"con\",\"tw\",\"call\",\"all\"]\n",
    "for i in range(0,len(ftypes)):\n",
    "    X = Xer(train_data, ftypes[i])\n",
    "    y = YerCutOff(train_label, 15).reshape(255,)\n",
    "\n",
    "    scores.append(cross_validation.cross_val_score(eclf, X, y, cv=2, scoring='accuracy'))\n",
    "\n",
    "\n",
    "# for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "#     scores = cross_validation.cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CUSTOM ENSEMBLE CLASSIFIER SKELETON\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class EnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, clfs, weights=None):\n",
    "        self.clfs = clfs\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        for clf in self.clfs:\n",
    "            clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        self.classes_ = np.asarray([clf.predict(X) for clf in self.clfs])\n",
    "        if self.weights:\n",
    "            avg = self.predict_proba(X)\n",
    "\n",
    "            maj = np.apply_along_axis(lambda x: max(enumerate(x), key=operator.itemgetter(1))[0], axis=1, arr=avg)\n",
    "\n",
    "        else:\n",
    "            maj = np.asarray([np.argmax(np.bincount(self.classes_[:,c])) for c in range(self.classes_.shape[1])])\n",
    "\n",
    "        return maj\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        self.probas_ = [clf.predict_proba(X) for clf in self.clfs]\n",
    "        avg = np.average(self.probas_, axis=0, weights=self.weights)\n",
    "\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_leaf': [50, 51], 'n_estimators': [500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ RANDOM FOREST FEATURE SELECTION #############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 15).reshape(train_label.shape[0],)\n",
    "\n",
    "# rdc = RandomForestRegressor(max_depth=2, random_state=0)#,max_features=None)\n",
    "rdc = RandomForestRegressor(random_state=0, max_features=None)\n",
    "\n",
    "# clf.fit(X, y)\n",
    "\n",
    "n_estimators = list(range(500,501))\n",
    "max_features = [\"auto\",\"sqrt\",\"log2\",0.2,0.4,0.6,0.8,None]\n",
    "min_sample_leaf = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf}\n",
    "max_depth = list(range(50,52))\n",
    "# parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "parameters = {'min_samples_leaf': min_sample_leaf, 'n_estimators':n_estimators}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rdc, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiue0qp1wAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcce5397e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## GRAPHING PHQ 9 DISTRIBUTION\n",
    "\n",
    "lizz = train_label[:,9:10].tolist()\n",
    "lizzn = []\n",
    "for i in range(0,len(lizz)):\n",
    "    lizzn.append(lizz[i][0])\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "Counter(lizzn)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels, values = zip(*Counter(lizzn).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "# indexes = indexes*4\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "# plt.xticks(indexes + width * 0.5, labels)\n",
    "# plt.tight_layout()\n",
    "# plt.figure(figsize=(30,50))\n",
    "# x = plt.axes([0,0,1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   4,   8,  12,  16,  20,  24,  28,  32,  36,  40,  44,  48,\n",
       "        52,  56,  60,  64,  68,  72,  76,  80,  84,  88,  92,  96, 100,\n",
       "       104, 108])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.156e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.078e-03, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 61 iterations, alpha=1.010e-03, previous alpha=1.009e-03, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/home/vape/.local/lib/python3.5/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(255, 0), dtype=float64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RLASSO SCORE EXPERIMENT\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "rlasso = RandomizedLasso()\n",
    "rlasso.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.075, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.02 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.015, 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.01 , 0.005, 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.03 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.015, 0.   , 0.   , 0.   , 0.   , 0.01 , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.04 , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   , 0.   , 0.   ,\n",
       "       0.015, 0.   , 0.   , 0.   , 0.035, 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.03 ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.005, 0.   , 0.035, 0.   , 0.   , 0.   , 0.005, 0.   , 0.   ,\n",
       "       0.   , 0.01 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.005, 0.   ,\n",
       "       0.   , 0.005, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlasso.scores_[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 1693)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xla = np.zeros((255, 1))\n",
    "\n",
    "for i in range(0,len(rlasso.scores_)):\n",
    "    if(rlasso.scores_[i] != 0):\n",
    "        Xla = np.hstack((Xla, X[:,i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xla = np.delete(Xla, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVC #############################\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = YerCutOff(train_label, 20).reshape(train_label.shape[0],)\n",
    "\n",
    "# parameters = {}\n",
    "\n",
    "# grid = GridSearchCV(regr, parameters, cv=2, scoring='explained_variance')\n",
    "# grid.fit(X, y)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold()\n",
    "X = sel.fit_transform(X)\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':list([0.001,0.01,0.1,1,2,3,4,5,6,7,8,10])}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.76863, std: 0.01870, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: 0.75294, std: 0.01864, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: 0.82353, std: 0.07382, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: 0.50196, std: 0.39413, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: 0.72157, std: 0.01286, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.03042, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: 0.77255, std: 0.01479, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: 0.75686, std: 0.01473, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: 0.74118, std: 0.02251, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: 0.69020, std: 0.01839, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 4, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 4, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 4, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 4, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 5, 'kernel': 'linear'},\n",
       " mean: 0.76471, std: 0.01476, params: {'C': 5, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 5, 'kernel': 'poly'},\n",
       " mean: 0.66667, std: 0.00523, params: {'C': 5, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 6, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 6, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 6, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 7, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 7, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 7, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 8, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 8, 'kernel': 'poly'},\n",
       " mean: 0.66275, std: 0.00917, params: {'C': 8, 'kernel': 'sigmoid'},\n",
       " mean: 0.72941, std: 0.00286, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: 0.76863, std: 0.01870, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: 0.65882, std: 0.01310, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n",
    "# grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xla, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.82      0.87       228\n",
      "        1.0       0.20      0.37      0.26        27\n",
      "\n",
      "avg / total       0.84      0.78      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xla)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 305)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(1.05))\n",
    "Xsel = sel.fit_transform(X)\n",
    "Xsel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.84706, std: 0.05158, params: {}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced', C=0.1, kernel='rbf')\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(Xsel, y)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.81      0.86       230\n",
      "        1.0       0.17      0.36      0.23        25\n",
      "\n",
      "avg / total       0.85      0.77      0.80       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = grid.predict(Xsel)\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHI^2 EXPERIMENT\n",
    "\n",
    "# X_new = SelectKBest(chi2, k=100).fit_transform(X, y)\n",
    "# X_new.shape\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "grid = GridSearchCV(svc, parameters, cv=2, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 66)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -48.36076, std: 4.91629, params: {'C': 0.001, 'kernel': 'linear'},\n",
       " mean: -48.48363, std: 5.11873, params: {'C': 0.001, 'kernel': 'rbf'},\n",
       " mean: -48.47340, std: 5.10615, params: {'C': 0.001, 'kernel': 'poly'},\n",
       " mean: -48.48446, std: 5.11947, params: {'C': 0.001, 'kernel': 'sigmoid'},\n",
       " mean: -48.30797, std: 4.56934, params: {'C': 0.005, 'kernel': 'linear'},\n",
       " mean: -48.47711, std: 5.11448, params: {'C': 0.005, 'kernel': 'rbf'},\n",
       " mean: -48.42917, std: 5.05056, params: {'C': 0.005, 'kernel': 'poly'},\n",
       " mean: -48.48173, std: 5.11783, params: {'C': 0.005, 'kernel': 'sigmoid'},\n",
       " mean: -48.84453, std: 3.90861, params: {'C': 0.01, 'kernel': 'linear'},\n",
       " mean: -48.46927, std: 5.10906, params: {'C': 0.01, 'kernel': 'rbf'},\n",
       " mean: -48.36964, std: 4.99038, params: {'C': 0.01, 'kernel': 'poly'},\n",
       " mean: -48.47940, std: 5.11517, params: {'C': 0.01, 'kernel': 'sigmoid'},\n",
       " mean: -55.87142, std: 2.88155, params: {'C': 0.1, 'kernel': 'linear'},\n",
       " mean: -48.33791, std: 5.02517, params: {'C': 0.1, 'kernel': 'rbf'},\n",
       " mean: -48.36671, std: 4.72774, params: {'C': 0.1, 'kernel': 'poly'},\n",
       " mean: -48.32661, std: 4.86574, params: {'C': 0.1, 'kernel': 'sigmoid'},\n",
       " mean: -86.93398, std: 13.02905, params: {'C': 1, 'kernel': 'linear'},\n",
       " mean: -48.09353, std: 4.93810, params: {'C': 1, 'kernel': 'rbf'},\n",
       " mean: -49.11536, std: 3.98500, params: {'C': 1, 'kernel': 'poly'},\n",
       " mean: -49.10748, std: 3.86566, params: {'C': 1, 'kernel': 'sigmoid'},\n",
       " mean: -102.49815, std: 15.76878, params: {'C': 2, 'kernel': 'linear'},\n",
       " mean: -48.76249, std: 5.03816, params: {'C': 2, 'kernel': 'rbf'},\n",
       " mean: -48.99617, std: 4.14751, params: {'C': 2, 'kernel': 'poly'},\n",
       " mean: -50.06255, std: 4.14031, params: {'C': 2, 'kernel': 'sigmoid'},\n",
       " mean: -112.84593, std: 15.88954, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: -49.93296, std: 4.56211, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: -49.04618, std: 4.33958, params: {'C': 3, 'kernel': 'poly'},\n",
       " mean: -51.04125, std: 4.20844, params: {'C': 3, 'kernel': 'sigmoid'},\n",
       " mean: -139.56998, std: 35.20001, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: -53.95925, std: 3.78778, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: -50.51646, std: 3.49427, params: {'C': 10, 'kernel': 'poly'},\n",
       " mean: -57.70473, std: 1.94329, params: {'C': 10, 'kernel': 'sigmoid'}]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ SVR #############################\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X = Xer(train_data, \"all\")\n",
    "y = Yer(train_label, 10).reshape(train_label.shape[0],)\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "c_range = [0.001,0.005,0.01,0.1,1,2,3,10]\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':c_range}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(svr, parameters, cv=2, scoring='neg_mean_squared_error')\n",
    "grid.fit(Xla, y)\n",
    "\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-48.09352610843258"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DEBUGGING BELLAS CODE\n",
    "\n",
    "import sqlite3 as sql\n",
    "import xml\n",
    "import xml.dom.minidom\n",
    "\n",
    "conn = sql.connect('phonedata.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "lizt = []\n",
    "gpsLookup = (1899, \"gps\")\n",
    "#for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "for row in c.execute('SELECT DISTINCT* FROM data WHERE id=? AND type=?', gpsLookup):\n",
    "    \n",
    "#     print row[2]\n",
    "    lizt.append(row[2])\n",
    "    \n",
    "    \n",
    "#number of different places visited by the user\n",
    "def numDiff(lizt):\n",
    "    sum = 0\n",
    "    for i in range(0, len(lizt)):\n",
    "        a = lizt[i]\n",
    "        xmldoc = xml.dom.minidom.parseString(a)\n",
    "        kml = xmldoc.getElementsByTagName(\"kml\")[0]\n",
    "        document = kml.getElementsByTagName(\"Document\")[0]\n",
    "        placemarks = document.getElementsByTagName(\"Placemark\")\n",
    "        \n",
    "        for placemark in placemarks:\n",
    "            desc = placemark.getElementsByTagName(\"description\")[0].firstChild.data\n",
    "            sum = sum + 1\n",
    "            \n",
    "            #print desc\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "numDiff(lizt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
