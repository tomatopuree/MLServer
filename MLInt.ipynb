{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "r = requests.get('http://depressionmqp.wpi.edu:8080/getids')\n",
    "list_of_ids = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_types = ['text','log','contact','calender','file','tweet']\n",
    "\n",
    "r = requests.get('http://depressionmqp.wpi.edu:8080/getids')\n",
    "list_of_idtime = r.json()\n",
    "list_of_ids = []\n",
    "list_of_times = []\n",
    "\n",
    "for i in range(0,len(list_of_idtime)):\n",
    "    list_of_ids.append( list_of_idtime[i]['id'].encode('ascii','ignore') )\n",
    "    \n",
    "for i in range(0,len(list_of_idtime)):\n",
    "    list_of_times.append( list_of_idtime[i]['date'] )\n",
    "\n",
    "#id1 = list_of_ids[0].encode('ascii','ignore')\n",
    "\n",
    "number_cols = len(list_of_types)\n",
    "number_rows = len(list_of_ids)\n",
    "list_of_jsons = [[0] * number_cols for i in range(number_rows)]\n",
    "\n",
    "for i in range(0,number_rows):\n",
    "    for j in range(0,number_cols):\n",
    "        temp = requests.get('http://depressionmqp.wpi.edu:8080/getdata?id=' + list_of_ids[i] + '&type=' + list_of_types[j])\n",
    "        list_of_jsons[i][j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1510437018202"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting text\n",
    "int(json.loads(list_of_jsons[0][0].json()[0])['date'].encode('ascii','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how u get the message\n",
    "# json.loads(list_of_jsons[0][0].json()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes in element of list_of_jsons and scrape date, spits out text frequency \n",
    "\n",
    "def textFreq(texts, scrapedate):\n",
    "    \n",
    "    a = texts.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    text_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        text_date = int(json.loads(a[len(a)-(i+1)])['date'].encode('ascii','ignore'))\n",
    "        if (two_weeks_prior < text_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    return float(saved_index+1)/14\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes in element of list_of_jsons(resp object) and scrape date, spits out call frequency \n",
    "\n",
    "def callFreq(calls, scrapedate):\n",
    "    \n",
    "    a = calls.json()\n",
    "    \n",
    "    seconds_intwo_weeks = 1209600;\n",
    "    \n",
    "    two_weeks_prior = scrapedate - seconds_intwo_weeks\n",
    "    \n",
    "    call_date = 0\n",
    "    saved_index = 0\n",
    "    \n",
    "    for i in range(0,len(a)):\n",
    "        call_date = int(json.loads(a[len(a)-(i+1)])['date'].encode('ascii','ignore'))\n",
    "        if (two_weeks_prior < call_date):\n",
    "            saved_index = len(a) - (i+1)\n",
    "            break\n",
    "    \n",
    "    return float(saved_index+1)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857],\n",
       "       [ 0.07142857,  0.07142857]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(list_of_jsons[0][1].json()[0])['date']\n",
    "\n",
    "## Making featureMatrix\n",
    "\n",
    "num_of_people = len(list_of_ids)\n",
    "\n",
    "featureVectorOne = np.zeros((num_of_people,1))\n",
    "featureVectorTwo = np.zeros((num_of_people,1))\n",
    "\n",
    "for i in range(0, num_of_people):\n",
    "    featureVectorTwo[i] = callFreq(list_of_jsons[i][1], list_of_times[i])\n",
    "    featureVectorOne[i] = textFreq(list_of_jsons[i][0], list_of_times[i])\n",
    "\n",
    "    \n",
    "featureMatrix = np.hstack((featureVectorOne,featureVectorTwo))\n",
    "\n",
    "featureMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "\n",
    "\n",
    "#model.similarity('turkey','islam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
